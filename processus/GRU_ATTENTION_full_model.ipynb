{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6033a233",
   "metadata": {},
   "source": [
    "# 1. Préparation des données, analyses et extraction des transcriptions\n",
    "\n",
    "## 1.1. Preparations des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf197416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d810b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torchaudio.transforms as T\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c3e261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de255ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les transcriptions\n",
    "df = pd.read_excel(\"C:/Users/Christian/Desktop/YembaTones/dataset2.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "582878a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordId</th>\n",
       "      <th>Yemba</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>GroupeId</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Syllabe 1</th>\n",
       "      <th>Tone 1</th>\n",
       "      <th>Syllabe 2</th>\n",
       "      <th>Tone 2</th>\n",
       "      <th>Syllabe 3</th>\n",
       "      <th>Tone 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>3780</td>\n",
       "      <td>lezēn</td>\n",
       "      <td>11</td>\n",
       "      <td>146</td>\n",
       "      <td>2</td>\n",
       "      <td>le</td>\n",
       "      <td>bas</td>\n",
       "      <td>zēn</td>\n",
       "      <td>moyen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>3781</td>\n",
       "      <td>nzeŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zeŋ</td>\n",
       "      <td>bas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>3782</td>\n",
       "      <td>nzéŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zéŋ</td>\n",
       "      <td>haut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>3783</td>\n",
       "      <td>nzɔ̄ŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zɔ̄ŋ</td>\n",
       "      <td>moyen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>3784</td>\n",
       "      <td>nzɔŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zɔŋ</td>\n",
       "      <td>bas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WordId   Yemba  Speaker  GroupeId  Statement Syllabe 1 Tone 1 Syllabe 2  \\\n",
       "3779    3780  lezēn       11       146          2        le    bas      zēn   \n",
       "3780    3781    nzeŋ       11       147          1         n    bas       zeŋ   \n",
       "3781    3782   nzéŋ       11       147          2         n    bas      zéŋ   \n",
       "3782    3783   nzɔ̄ŋ       11       148          1         n    bas      zɔ̄ŋ   \n",
       "3783    3784    nzɔŋ       11       148          2         n    bas       zɔŋ   \n",
       "\n",
       "     Tone 2 Syllabe 3 Tone 3  \n",
       "3779  moyen       NaN    NaN  \n",
       "3780    bas       NaN    NaN  \n",
       "3781   haut       NaN    NaN  \n",
       "3782  moyen       NaN    NaN  \n",
       "3783    bas       NaN    NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c6996b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordId          0\n",
      "Yemba           0\n",
      "Speaker         0\n",
      "GroupeId        0\n",
      "Statement       0\n",
      "Syllabe 1       0\n",
      "Tone 1          0\n",
      "Syllabe 2      22\n",
      "Tone 2         22\n",
      "Syllabe 3    3762\n",
      "Tone 3       3762\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c09d225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83225fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression définitive des colonnes Syllabe 3 et Tone 3\n",
    "df.drop(columns=[\"Syllabe 3\", \"Tone 3\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc0548a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacement des valeurs manquates\n",
    "df[\"Syllabe 2\"] = df[\"Syllabe 2\"].fillna(\"∅\")\n",
    "df[\"Tone 2\"]    = df[\"Tone 2\"].fillna(\"∅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25d2a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les lignes où Syllabe 2 OU Tone 2 sont manquants ou égaux à \"∅\"\n",
    "df = df[~((df[\"Syllabe 2\"] == \"∅\") | (df[\"Tone 2\"] == \"∅\"))]\n",
    "df = df.reset_index(drop=True)  # Reindexer proprement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69570c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génère les chemins des fichiers audio associés\n",
    "def get_audio_path(row):\n",
    "    return f\"C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_{row['Speaker']}/group_{row['GroupeId']}/spkr_{row['Speaker']}_group_{row['GroupeId']}_statement_{int(row['Statement'])}.wav\"\n",
    "\n",
    "df[\"audio_path\"] = df.apply(get_audio_path, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec0cf1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordId</th>\n",
       "      <th>Yemba</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>GroupeId</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Syllabe 1</th>\n",
       "      <th>Tone 1</th>\n",
       "      <th>Syllabe 2</th>\n",
       "      <th>Tone 2</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>3780</td>\n",
       "      <td>lezēn</td>\n",
       "      <td>11</td>\n",
       "      <td>146</td>\n",
       "      <td>2</td>\n",
       "      <td>le</td>\n",
       "      <td>bas</td>\n",
       "      <td>zēn</td>\n",
       "      <td>moyen</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_146/spkr_11_group_146_statement_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>3781</td>\n",
       "      <td>nzeŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zeŋ</td>\n",
       "      <td>bas</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_147/spkr_11_group_147_statement_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>3782</td>\n",
       "      <td>nzéŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zéŋ</td>\n",
       "      <td>haut</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_147/spkr_11_group_147_statement_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>3783</td>\n",
       "      <td>nzɔ̄ŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zɔ̄ŋ</td>\n",
       "      <td>moyen</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_148/spkr_11_group_148_statement_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>3784</td>\n",
       "      <td>nzɔŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zɔŋ</td>\n",
       "      <td>bas</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_148/spkr_11_group_148_statement_2.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WordId   Yemba  Speaker  GroupeId  Statement Syllabe 1 Tone 1 Syllabe 2  \\\n",
       "3757    3780  lezēn       11       146          2        le    bas      zēn   \n",
       "3758    3781    nzeŋ       11       147          1         n    bas       zeŋ   \n",
       "3759    3782   nzéŋ       11       147          2         n    bas      zéŋ   \n",
       "3760    3783   nzɔ̄ŋ       11       148          1         n    bas      zɔ̄ŋ   \n",
       "3761    3784    nzɔŋ       11       148          2         n    bas       zɔŋ   \n",
       "\n",
       "     Tone 2  \\\n",
       "3757  moyen   \n",
       "3758    bas   \n",
       "3759   haut   \n",
       "3760  moyen   \n",
       "3761    bas   \n",
       "\n",
       "                                                                                                                                                                                                   audio_path  \n",
       "3757  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_146/spkr_11_group_146_statement_2.wav  \n",
       "3758  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_147/spkr_11_group_147_statement_1.wav  \n",
       "3759  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_147/spkr_11_group_147_statement_2.wav  \n",
       "3760  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_148/spkr_11_group_148_statement_1.wav  \n",
       "3761  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_148/spkr_11_group_148_statement_2.wav  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33662dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les syllabes avec tons pour créer une transcription syllabique\n",
    "def combine_syllables(row):\n",
    "    syllables = []\n",
    "    for i in range(1, 4):\n",
    "        syll = row.get(f\"Syllabe {i}\")\n",
    "        tone = row.get(f\"Tone {i}\")\n",
    "        if pd.notnull(syll) and pd.notnull(tone):\n",
    "            syllables.append(f\"{syll}|{tone}\")\n",
    "    return \" \".join(syllables)\n",
    "\n",
    "df[\"syllable_transcript\"] = df.apply(combine_syllables, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37d722b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordId</th>\n",
       "      <th>Yemba</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>GroupeId</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Syllabe 1</th>\n",
       "      <th>Tone 1</th>\n",
       "      <th>Syllabe 2</th>\n",
       "      <th>Tone 2</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>syllable_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Apa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pa</td>\n",
       "      <td>bas</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_1.wav</td>\n",
       "      <td>a|bas pa|bas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Apā</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pā</td>\n",
       "      <td>moyen</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_2.wav</td>\n",
       "      <td>a|bas pā|moyen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Apá</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pá</td>\n",
       "      <td>haut</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_3.wav</td>\n",
       "      <td>a|bas pá|haut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Api</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pi</td>\n",
       "      <td>bas</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_1.wav</td>\n",
       "      <td>a|bas pi|bas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Apī</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pī</td>\n",
       "      <td>moyen</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_2.wav</td>\n",
       "      <td>a|bas pī|moyen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WordId Yemba  Speaker  GroupeId  Statement Syllabe 1 Tone 1 Syllabe 2  \\\n",
       "0       1   Apa        1         1          1         a    bas        pa   \n",
       "1       2  Apā        1         1          2         a    bas       pā   \n",
       "2       3  Apá        1         1          3         a    bas       pá   \n",
       "3       4   Api        1         2          1         a    bas        pi   \n",
       "4       5  Apī        1         2          2         a    bas       pī   \n",
       "\n",
       "   Tone 2  \\\n",
       "0     bas   \n",
       "1   moyen   \n",
       "2    haut   \n",
       "3     bas   \n",
       "4  moyen    \n",
       "\n",
       "                                                                                                                                                                                          audio_path  \\\n",
       "0  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_1.wav   \n",
       "1  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_2.wav   \n",
       "2  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_3.wav   \n",
       "3  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_1.wav   \n",
       "4  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_2.wav   \n",
       "\n",
       "  syllable_transcript  \n",
       "0        a|bas pa|bas  \n",
       "1     a|bas pā|moyen  \n",
       "2      a|bas pá|haut  \n",
       "3        a|bas pi|bas  \n",
       "4    a|bas pī|moyen   "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0613d02",
   "metadata": {},
   "source": [
    "## 1.2. Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3632b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordId</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>GroupeId</th>\n",
       "      <th>Statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3762.000000</td>\n",
       "      <td>3762.000000</td>\n",
       "      <td>3762.000000</td>\n",
       "      <td>3762.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1892.307018</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>71.409357</td>\n",
       "      <td>1.730994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1092.515348</td>\n",
       "      <td>3.162698</td>\n",
       "      <td>42.952047</td>\n",
       "      <td>0.743985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>947.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1891.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2837.750000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3784.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            WordId      Speaker     GroupeId    Statement\n",
       "count  3762.000000  3762.000000  3762.000000  3762.000000\n",
       "mean   1892.307018     6.000000    71.409357     1.730994\n",
       "std    1092.515348     3.162698    42.952047     0.743985\n",
       "min       1.000000     1.000000     1.000000     1.000000\n",
       "25%     947.250000     3.000000    33.000000     1.000000\n",
       "50%    1891.500000     6.000000    68.500000     2.000000\n",
       "75%    2837.750000     9.000000   109.000000     2.000000\n",
       "max    3784.000000    11.000000   149.000000     4.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13cab3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 syllabes les plus fréquentes :\n",
      "n      1287\n",
      "Le      924\n",
      "m       462\n",
      "a       440\n",
      "ŋ       176\n",
      "N       143\n",
      "le       99\n",
      "Me       66\n",
      "gap      44\n",
      "tā      33\n",
      "dtype: int64\n",
      "\n",
      "Nombre total de syllabes uniques : 301\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Compter toutes les syllabes\n",
    "syllabes = pd.concat([df['Syllabe 1'], df['Syllabe 2']])\n",
    "syllabe_counts = syllabes.value_counts()\n",
    "\n",
    "# Afficher les 10 syllabes les plus fréquentes\n",
    "print(\"Top 10 syllabes les plus fréquentes :\")\n",
    "print(syllabe_counts.head(10))\n",
    "\n",
    "# Afficher le nombre total de syllabes uniques\n",
    "print(f\"\\nNombre total de syllabes uniques : {syllabe_counts.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5b456b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n        1287\n",
      "Le        924\n",
      "m         462\n",
      "a         440\n",
      "ŋ         176\n",
      "N         143\n",
      "le         99\n",
      "Me         66\n",
      "gap        44\n",
      "tā        33\n",
      "zɔ̄ŋ       33\n",
      "kwɛ̄t      33\n",
      "lúŋ       33\n",
      "ń         33\n",
      "lūŋ       33\n",
      "M          33\n",
      "zɔŋ        22\n",
      "tsɔ́ŋ      22\n",
      "tshí      22\n",
      "cɔ̄k       22\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAAGGCAYAAACNL1mYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABiKklEQVR4nO3deZyN9f//8ecxm8HMMJaZLKEae7LLqJB9XypEtkZalIQsSahQfJI+ydKnJFnbaCG7FJJlLJEl2bOHGcuY9fX7w2/O1zGIyZlzhsf9dptbneu8zzmv63LNNdfzer+v93GYmQkAAAAAALhFFk8XAAAAAADArYzgDQAAAACAGxG8AQAAAABwI4I3AAAAAABuRPAGAAAAAMCNCN4AAAAAALgRwRsAAAAAADcieAMAAAAA4EYEbwAAAAAA3IjgDQAA4Cbt27dX8eLFdeLECU+XAgDwIII3ANxmHA7Hdf38+OOPbq3j8OHDevXVV1WtWjXlyZNHwcHBqlixoj788EMlJyenaX/27Fn17NlT+fPnV9asWVWuXDnNnDnTrTVeSZEiRdS5c2fn471798rhcGjy5Mk3/F4//vijHA6Hvvzyy5tXYDql1uLuf/f06ty5s4oUKZLhnztr1iyVLl1agYGBcjgc2rhx43W/dsKECVqyZInmz5+vPHnyuK9INzl//ryGDBnitfsEAGQmvp4uAACQsX755ReXx2+88YaWLVumpUuXuiwvVaqUW+tYv369pkyZoo4dO2rQoEHy8/PTDz/8oGeffVarV6/WpEmTXNq3atVKa9eu1VtvvaVixYpp+vTpevzxx5WSkqJ27dq5tVbcno4fP64OHTqoQYMGGjdunAICAlSsWLHrem10dLQGDRqkBQsWqGjRom6u1D3Onz+voUOHSpJq1qzp2WIAIJMjeAPAbeb+++93eZw3b15lyZIlzXJ3q169uv7880/5+fk5l9WtW1cJCQn64IMPNHToUBUqVEiSNG/ePC1atMgZtiWpVq1a2rdvn15++WW1adNGPj4+GVo/bn07d+5UYmKinnjiCdWoUeOabc+fP69s2bI5H1eoUEHHjx93d4kAgEyCoeYAgDROnjyp5557TgUKFJC/v7/uuusuDRw4UPHx8S7tHA6Hnn/+eU2cOFHFihVTQECASpUqdV1DwHPlyuUSulNVqVJFknTw4EHnstmzZytHjhx67LHHXNp26dJFhw4d0q+//nrNz9q9e7fatm2r/PnzKyAgQGFhYapdu7Zz2HBUVJRCQ0N1/vz5NK99+OGHVbp06X9cn0vt2rVLXbp0UUREhLJly6YCBQqoadOm+u23367Y/sKFC+rVq5fCw8MVGBioGjVqaMOGDWnarVu3Ts2aNVNoaKiyZs2q8uXL6/PPP3dpc/78efXp00dFixZV1qxZFRoaqkqVKmnGjBk3tA4Z8ZmTJ0+Ww+HQokWL1KVLF4WGhip79uxq2rSpdu/efc3XXmuIv8Ph0JAhQ5yPjx8/rm7duqlQoUIKCAhQ3rx5Vb16dS1evPiq79+5c2c98MADkqQ2bdrI4XA4e307d+6sHDly6LffflO9evUUFBSk2rVrS5ISEhL05ptvqkSJEs7P6tKlS5oQnpiYqL59+yo8PFzZsmXTAw88oDVr1qS5lWHIkCFyOBxX3XZ79+51WT5r1ixVq1ZN2bNnV44cOVS/fv00+1Jq/bt27VKjRo2UI0cOFSpUSL1793b+ju/du1d58+aVJA0dOtR5C8qltf3xxx9q166d8uXLp4CAAJUsWVIffPCBy2elpKTozTffVPHixRUYGKicOXOqbNmyeu+996667QHgVkSPNwDAxYULF1SrVi39+eefGjp0qMqWLauff/5ZI0aM0MaNGzV37lyX9t9++62WLVum119/XdmzZ9e4ceP0+OOPy9fXV48++ugNf/7SpUvl6+vrMqR3y5YtKlmypHx9Xf9slS1b1vl8ZGTkVd+zUaNGSk5O1siRI3XnnXfqxIkTWrVqlU6fPi1JevHFFzVp0iRNnz5dXbt2db7u999/17Jly9KEiX9y6NAh5c6dW2+99Zby5s2rkydP6tNPP1XVqlW1YcMGFS9e3KX9K6+8ogoVKuijjz5STEyMhgwZopo1a2rDhg266667JEnLli1TgwYNVLVqVU2YMEEhISGaOXOm2rRpo/PnzzsDUa9evfTZZ5/pzTffVPny5XXu3Dlt2bJFf//99w2tQ0Z+ZlRUlOrWravp06frwIEDevXVV1WzZk1t3rxZOXPmvOG6L9ehQwdFR0dr2LBhKlasmE6fPq3o6Ohr1jdo0CBVqVJF3bt31/Dhw1WrVi0FBwc7n09ISFCzZs309NNPq3///kpKSlJKSoqaN2+un3/+WX379lVkZKT27dunwYMHq2bNmlq3bp0CAwMlSU899ZSmTJmiPn36qG7dutqyZYtatWqlM2fOpHs9hw8frldffVVdunTRq6++qoSEBI0aNUoPPvig1qxZ43L7SGJiopo1a6aoqCj17t1bP/30k9544w2FhITotdde0x133KH58+erQYMGioqKcv5epIbx33//XZGRkbrzzjv1zjvvKDw8XAsWLFCPHj104sQJDR48WJI0cuRIDRkyRK+++qoeeughJSYmavv27c7fPQC4bRgA4LbWqVMny549u/PxhAkTTJJ9/vnnLu3efvttk2QLFy50LpNkgYGBduTIEeeypKQkK1GihN1zzz03XMuCBQssS5Ys9tJLL7ksj4iIsPr166dpf+jQIZNkw4cPv+p7njhxwiTZmDFjrvnZNWrUsHLlyrkse/bZZy04ONjOnDnjXFa4cGHr1KmT8/GePXtMkn3yySdXfe+kpCRLSEiwiIgIl3VbtmyZSbIKFSpYSkqKc/nevXvNz8/Punbt6lxWokQJK1++vCUmJrq8d5MmTeyOO+6w5ORkMzMrU6aMtWjR4prreiWptSxbtizDPvOTTz4xSdayZUuX5StXrjRJ9uabbzqXderUyQoXLux8fK3tLskGDx7sfJwjRw7r2bPnDdeXuk2++OILl+WdOnUySTZp0iSX5TNmzDBJ9tVXX7ksX7t2rUmycePGmZnZtm3bTFKa/XzatGkmyWX/Gjx4sF3pdC112+3Zs8fMzPbv32++vr72wgsvuLQ7c+aMhYeHW+vWrdPUf/nveKNGjax48eLOx8ePH0+zLVPVr1/fChYsaDExMS7Ln3/+ecuaNaudPHnSzC7uK5f/XgHA7Yih5gAAF0uXLlX27NnT9Fan9m4uWbLEZXnt2rUVFhbmfOzj46M2bdpo165dLsPF/0l0dLRat26t+++/XyNGjEjz/JWG217Pc6Ghobr77rs1atQojR49Whs2bFBKSkqadi+++KI2btyolStXSpJiY2P12WefqVOnTsqRI8d1r4ckJSUlafjw4SpVqpT8/f3l6+srf39//fHHH9q2bVua9u3atXNZh8KFCysyMlLLli2TdHHo+vbt29W+fXvn+6f+NGrUSIcPH9aOHTskXRyq/8MPP6h///768ccfFRcXd0O1p8rIz0z9jFSRkZEqXLiwc/3/rSpVqmjy5Ml68803tXr1aiUmJt6U933kkUdcHn///ffKmTOnmjZt6rK9ypUrp/DwcOfs4Knrdfl6t27dOs2ojuu1YMECJSUlqWPHji6fnTVrVtWoUSPNzOQOh0NNmzZ1WVa2bFnt27fvHz/rwoULWrJkiVq2bKls2bKl2TcuXLig1atXS7q47Tdt2qTnnntOCxYsUGxsbLrWDwAyO4I3AMDF33//rfDw8DRhNl++fPL19U0zPDc8PDzNe6Quu96hxhs2bFDdunUVERGhefPmKSAgwOX53LlzX/G9Tp48KeliuL4ah8OhJUuWqH79+ho5cqQqVKigvHnzqkePHi7Deps3b64iRYo4h5VPnjxZ586dU/fu3a9rHS7Vq1cvDRo0SC1atNB3332nX3/9VWvXrtV99913xVB6tW2Yus5Hjx6VJPXp00d+fn4uP88995wkOb8n+r///a/69eunOXPmqFatWgoNDVWLFi30xx9/3NA6ZORn/tP6/1uzZs1Sp06d9NFHH6latWoKDQ1Vx44ddeTIkXS/Z7Zs2VyGnksXt9np06fl7++fZpsdOXLEub1S1+vy9fb19VXu3LnTVU/qv1flypXTfPasWbPSfI94tmzZlDVrVpdlAQEBunDhwj9+1t9//62kpCS9//77aT6rUaNGkv5v3xgwYID+85//aPXq1WrYsKFy586t2rVra926delaTwDIrLjHGwDgInfu3Pr1119lZi7h+9ixY0pKSkrzfcRXCi+py64nRGzYsEF16tRR4cKFtXDhQoWEhKRpc++992rGjBlKSkpy6RFMnaysTJky1/yMwoUL6+OPP5Z0cabqzz//XEOGDFFCQoImTJggScqSJYu6d++uV155Re+8847GjRun2rVrp7kf+3pMnTpVHTt21PDhw12Wnzhx4or3LF9tG6Zuv9RtPmDAALVq1eqKn5laZ/bs2TV06FANHTpUR48edfZEN23aVNu3b7/udcjIz7za+t9zzz1XfU1qaLx8wr8rhfU8efJozJgxGjNmjPbv369vv/1W/fv317FjxzR//vx/rO9KrjTKIk+ePMqdO/dV3zMoKEjS//1eHDlyRAUKFHA+n5SUlKb+S9fz0gtSlwfp1H+vL7/8UoULF77R1bkhuXLlko+Pjzp06HDVC1OpX6Hm6+urXr16qVevXjp9+rQWL16sV155RfXr19eBAwdcZoIHgFsZwRsA4KJ27dr6/PPPNWfOHLVs2dK5fMqUKc7nL7VkyRIdPXrUOdw8OTlZs2bN0t13362CBQte87M2btyoOnXqqGDBglq0aJFy5cp1xXYtW7bU//73P3311Vdq06aNc/mnn36q/Pnzq2rVqte9fsWKFdOrr76qr776StHR0S7Pde3aVUOGDFH79u21Y8cOvf3229f9vpdyOBxpeu3nzp2rv/7664phcsaMGerVq5czzO3bt0+rVq1Sx44dJV0MuBEREdq0aVOaMH8tYWFh6ty5szZt2qQxY8ak+cqra8nIz5w2bZrLsO1Vq1Zp3759LhPdXelzsmbNqs2bN7ss/+abb675WXfeeaeef/55LVmyxHlbwc3SpEkTzZw5U8nJydfcJ1NnR582bZoqVqzoXP75558rKSnJpW2RIkUkSZs3b1blypWdy7/77juXdvXr15evr6/+/PPPNEPg0yt1H758lEa2bNlUq1YtbdiwQWXLlpW/v/91vV/OnDn16KOP6q+//lLPnj21d+9elwnfAOBWRvAGALjo2LGjPvjgA3Xq1El79+7VvffeqxUrVmj48OFq1KiR6tSp49I+T548evjhhzVo0CDnrObbt2//x68U27Fjh/O9hg0bpj/++MNlaPLdd9/tnEG5YcOGqlu3rp599lnFxsbqnnvu0YwZMzR//nxNnTr1mt/hvXnzZj3//PN67LHHFBERIX9/fy1dulSbN29W//79XdrmzJlTHTt21Pjx41W4cOE098BeryZNmmjy5MkqUaKEypYtq/Xr12vUqFFXvRBx7NgxtWzZUk899ZRiYmI0ePBgZc2aVQMGDHC2mThxoho2bKj69eurc+fOKlCggE6ePKlt27YpOjpaX3zxhSSpatWqatKkicqWLatcuXJp27Zt+uyzz1StWrUb7l3MqM9ct26dunbtqscee0wHDhzQwIEDVaBAAeeQ9itxOBx64oknNGnSJN1999267777tGbNGk2fPt2lXUxMjGrVqqV27dqpRIkSCgoK0tq1azV//vyr9uSnV9u2bTVt2jQ1atRIL774oqpUqSI/Pz8dPHhQy5YtU/PmzdWyZUuVLFlSTzzxhMaMGSM/Pz/VqVNHW7Zs0X/+8580w9cbNWqk0NBQRUVF6fXXX5evr68mT56sAwcOuLQrUqSIXn/9dQ0cOFC7d+9WgwYNlCtXLh09elRr1qxxjkq4EUFBQSpcuLC++eYb1a5dW6GhocqTJ4+KFCmi9957Tw888IAefPBBPfvssypSpIjOnDmjXbt26bvvvtPSpUslSU2bNlWZMmVUqVIl5c2bV/v27dOYMWNUuHBhRURE/LsNDgCZiadndwMAeNbls5qbmf3999/2zDPP2B133GG+vr5WuHBhGzBggF24cMGlnSTr3r27jRs3zu6++27z8/OzEiVK2LRp0/7xc1NnZb7az+WzVZ85c8Z69Ohh4eHh5u/vb2XLlrUZM2b84+ccPXrUOnfubCVKlLDs2bNbjhw5rGzZsvbuu+9aUlJSmvY//vijSbK33nrriu93PbOanzp1yqKioixfvnyWLVs2e+CBB+znn3+2GjVqWI0aNZztUmfN/uyzz6xHjx6WN29eCwgIsAcffNDWrVuX5rM3bdpkrVu3tnz58pmfn5+Fh4fbww8/bBMmTHC26d+/v1WqVMly5cplAQEBdtddd9lLL71kJ06cuOZ2utKs5u7+zNR9YOHChdahQwfLmTOnBQYGWqNGjeyPP/5waXv5rOZmZjExMda1a1cLCwuz7NmzW9OmTW3v3r0uM3FfuHDBnnnmGStbtqwFBwdbYGCgFS9e3AYPHmznzp27rm1ypVnNL/+dSZWYmGj/+c9/7L777rOsWbNajhw5rESJEvb000+7rFN8fLz17t3b8uXLZ1mzZrX777/ffvnllzT7l5nZmjVrLDIy0rJnz24FChSwwYMH20cffeQyq3mqOXPmWK1atSw4ONgCAgKscOHC9uijj9rixYv/sf4rzaC+ePFiK1++vAUEBKSZcX3Pnj325JNPWoECBczPz8/y5s1rkZGRLrPRv/POOxYZGWl58uQxf39/u/POOy0qKsr27t17xe0HALcqh5lZRod9AMCtweFwqHv37ho7dqynS7lpevfurfHjx+vAgQPpnugK12fy5Mnq0qWL1q5dq0qVKnm6HK9QpEgR1axZU5MnT/Z0KQCAm4ih5gAASFq9erV27typcePG6emnnyZ0AwCAm4bgDQCA5LwfuUmTJnrzzTc9XQ4AALiFMNQcAAAAAAA3yuLpAgAAAAAAuJURvAEAAAAAcCOCNwAAAAAAbsTkatcpJSVFhw4dUlBQkBwOh6fLAQAAAAB4kJnpzJkzyp8/v7JkuXafNsH7Oh06dEiFChXydBkAAAAAAC9y4MABFSxY8JptCN7XKSgoSNLFjRocHOzhagAAAAAAnhQbG6tChQo5s+K1ELyvU+rw8uDgYII3AAAAAECSrutWZCZXAwAAAADAjQjeAAAAAAC4EcEbAAAAAAA3IngDAAAAAOBGBG8AAAAAANyI4A0AAAAAgBsRvAEAAAAAcCOCNwAAAAAAbkTwBgAAAADAjQjeAAAAAAC4EcEbAAAAAAA3IngDAAAAAOBGvp4u4FZWpP9ct7zv3rcau+V9AQAAAAA3Hz3eAAAAAAC4EcEbAAAAAAA3IngDAAAAAOBGBG8AAAAAANyI4A0AAAAAgBsRvAEAAAAAcCOCNwAAAAAAbkTwBgAAAADAjQjeAAAAAAC4EcEbAAAAAAA3IngDAAAAAOBGBG8AAAAAANyI4A0AAAAAgBsRvAEAAAAAcCOPB++ffvpJTZs2Vf78+eVwODRnzhznc4mJierXr5/uvfdeZc+eXfnz51fHjh116NAhl/eIj4/XCy+8oDx58ih79uxq1qyZDh486NLm1KlT6tChg0JCQhQSEqIOHTro9OnTGbCGAAAAAIDbmceD97lz53Tfffdp7NixaZ47f/68oqOjNWjQIEVHR+vrr7/Wzp071axZM5d2PXv21OzZszVz5kytWLFCZ8+eVZMmTZScnOxs065dO23cuFHz58/X/PnztXHjRnXo0MHt6wcAAAAAuL05zMw8XUQqh8Oh2bNnq0WLFldts3btWlWpUkX79u3TnXfeqZiYGOXNm1efffaZ2rRpI0k6dOiQChUqpHnz5ql+/fratm2bSpUqpdWrV6tq1aqSpNWrV6tatWravn27ihcv/o+1xcbGKiQkRDExMQoODr6u9SnSf+51tbtRe99q7Jb3BQAAAABcnxvJiB7v8b5RMTExcjgcypkzpyRp/fr1SkxMVL169Zxt8ufPrzJlymjVqlWSpF9++UUhISHO0C1J999/v0JCQpxtAAAAAABwB19PF3AjLly4oP79+6tdu3bOKwpHjhyRv7+/cuXK5dI2LCxMR44ccbbJly9fmvfLly+fs83l4uPjFR8f73wcGxt7s1YDAAAAAHAbyTQ93omJiWrbtq1SUlI0bty4f2xvZnI4HM7Hl/7/1dpcasSIEc6J2EJCQlSoUKH0Fw8AAAAAuG1liuCdmJio1q1ba8+ePVq0aJHL+Pnw8HAlJCTo1KlTLq85duyYwsLCnG2OHj2a5n2PHz/ubHO5AQMGKCYmxvlz4MCBm7hGAAAAAIDbhdcH79TQ/ccff2jx4sXKnTu3y/MVK1aUn5+fFi1a5Fx2+PBhbdmyRZGRkZKkatWqKSYmRmvWrHG2+fXXXxUTE+Nsc7mAgAAFBwe7/AAAAAAAcKM8fo/32bNntWvXLufjPXv2aOPGjQoNDVX+/Pn16KOPKjo6Wt9//72Sk5Od92SHhobK399fISEhioqKUu/evZU7d26FhoaqT58+uvfee1WnTh1JUsmSJdWgQQM99dRTmjhxoiSpW7duatKkyXXNaA4AAAAAQHp5PHivW7dOtWrVcj7u1auXJKlTp04aMmSIvv32W0lSuXLlXF63bNky1axZU5L07rvvytfXV61bt1ZcXJxq166tyZMny8fHx9l+2rRp6tGjh3P282bNml3xu8MBAAAAALiZvOp7vL0Z3+MNAAAAAEh1S3+PNwAAAAAAmQnBGwAAAAAANyJ4AwAAAADgRgRvAAAAAADciOANAAAAAIAbEbwBAAAAAHAjgjcAAAAAAG5E8AYAAAAAwI0I3gAAAAAAuBHBGwAAAAAANyJ4AwAAAADgRgRvAAAAAADciOANAAAAAIAbEbwBAAAAAHAjgjcAAAAAAG5E8AYAAAAAwI0I3gAAAAAAuBHBGwAAAAAANyJ4AwAAAADgRgRvAAAAAADciOANAAAAAIAbEbwBAAAAAHAjgjcAAAAAAG5E8AYAAAAAwI0I3gAAAAAAuBHBGwAAAAAANyJ4AwAAAADgRgRvAAAAAADciOANAAAAAIAbEbwBAAAAAHAjgjcAAAAAAG5E8AYAAAAAwI0I3gAAAAAAuBHBGwAAAAAAN/J48P7pp5/UtGlT5c+fXw6HQ3PmzHF53sw0ZMgQ5c+fX4GBgapZs6a2bt3q0iY+Pl4vvPCC8uTJo+zZs6tZs2Y6ePCgS5tTp06pQ4cOCgkJUUhIiDp06KDTp0+7ee0AAAAAALc7jwfvc+fO6b777tPYsWOv+PzIkSM1evRojR07VmvXrlV4eLjq1q2rM2fOONv07NlTs2fP1syZM7VixQqdPXtWTZo0UXJysrNNu3bttHHjRs2fP1/z58/Xxo0b1aFDB7evHwAAAADg9uYwM/N0EakcDodmz56tFi1aSLrY250/f3717NlT/fr1k3SxdzssLExvv/22nn76acXExChv3rz67LPP1KZNG0nSoUOHVKhQIc2bN0/169fXtm3bVKpUKa1evVpVq1aVJK1evVrVqlXT9u3bVbx48X+sLTY2ViEhIYqJiVFwcPB1rU+R/nPTsRX+2d63GrvlfQEAAAAA1+dGMqLHe7yvZc+ePTpy5Ijq1avnXBYQEKAaNWpo1apVkqT169crMTHRpU3+/PlVpkwZZ5tffvlFISEhztAtSffff79CQkKcbQAAAAAAcAdfTxdwLUeOHJEkhYWFuSwPCwvTvn37nG38/f2VK1euNG1SX3/kyBHly5cvzfvny5fP2eZy8fHxio+Pdz6OjY1N/4oAAAAAAG5bXt3jncrhcLg8NrM0yy53eZsrtb/W+4wYMcI5EVtISIgKFSqUjsoBAAAAALc7rw7e4eHhkpSmV/rYsWPOXvDw8HAlJCTo1KlT12xz9OjRNO9//PjxNL3pqQYMGKCYmBjnz4EDB/71+gAAAAAAbj9eHbyLFi2q8PBwLVq0yLksISFBy5cvV2RkpCSpYsWK8vPzc2lz+PBhbdmyxdmmWrVqiomJ0Zo1a5xtfv31V8XExDjbXC4gIEDBwcEuPwAAAAAA3CiP3+N99uxZ7dq1y/l4z5492rhxo0JDQ3XnnXeqZ8+eGj58uCIiIhQREaHhw4crW7ZsateunSQpJCREUVFR6t27t3Lnzq3Q0FD16dNH9957r+rUqSNJKlmypBo0aKCnnnpKEydOlCR169ZNTZo0ua4ZzQEAAAAASC+PB+9169apVq1azse9evWSJHXq1EmTJ09W3759FRcXp+eee06nTp1S1apVtXDhQgUFBTlf8+6778rX11etW7dWXFycateurcmTJ8vHx8fZZtq0aerRo4dz9vNmzZpd9bvDAQAAAAC4Wbzqe7y9Gd/jDQAAAABIdct8jzcAAAAAAJkdwRsAAAAAADcieAMAAAAA4EYEbwAAAAAA3IjgDQAAAACAGxG8AQAAAABwI4I3AAAAAABuRPAGAAAAAMCNCN4AAAAAALgRwRsAAAAAADcieAMAAAAA4Ea+ni4A3qVI/7lued+9bzV2y/sCAAAAgLejxxsAAAAAADcieAMAAAAA4EYEbwAAAAAA3IjgDQAAAACAGxG8AQAAAABwI4I3AAAAAABuRPAGAAAAAMCNCN4AAAAAALgRwRsAAAAAADcieAMAAAAA4EYEbwAAAAAA3IjgDQAAAACAGxG8AQAAAABwI4I3AAAAAABuRPAGAAAAAMCNCN4AAAAAALgRwRsAAAAAADcieAMAAAAA4EYEbwAAAAAA3IjgDQAAAACAGxG8AQAAAABwI4I3AAAAAABu9K+D965du7RgwQLFxcVJkszsXxcFAAAAAMCtIt3B+++//1adOnVUrFgxNWrUSIcPH5Ykde3aVb17975pBSYlJenVV19V0aJFFRgYqLvuukuvv/66UlJSnG3MTEOGDFH+/PkVGBiomjVrauvWrS7vEx8frxdeeEF58uRR9uzZ1axZMx08ePCm1QkAAAAAwJWkO3i/9NJL8vX11f79+5UtWzbn8jZt2mj+/Pk3pThJevvttzVhwgSNHTtW27Zt08iRIzVq1Ci9//77zjYjR47U6NGjNXbsWK1du1bh4eGqW7euzpw542zTs2dPzZ49WzNnztSKFSt09uxZNWnSRMnJyTetVgAAAAAALueb3hcuXLhQCxYsUMGCBV2WR0REaN++ff+6sFS//PKLmjdvrsaNG0uSihQpohkzZmjdunWSLvZ2jxkzRgMHDlSrVq0kSZ9++qnCwsI0ffp0Pf3004qJidHHH3+szz77THXq1JEkTZ06VYUKFdLixYtVv379m1YvAAAAAACXSneP97lz51x6ulOdOHFCAQEB/6qoSz3wwANasmSJdu7cKUnatGmTVqxYoUaNGkmS9uzZoyNHjqhevXrO1wQEBKhGjRpatWqVJGn9+vVKTEx0aZM/f36VKVPG2eZy8fHxio2NdfkBAAAAAOBGpTt4P/TQQ5oyZYrzscPhUEpKikaNGqVatWrdlOIkqV+/fnr88cdVokQJ+fn5qXz58urZs6cef/xxSdKRI0ckSWFhYS6vCwsLcz535MgR+fv7K1euXFdtc7kRI0YoJCTE+VOoUKGbtk4AAAAAgNtHuoeajxo1SjVr1tS6deuUkJCgvn37auvWrTp58qRWrlx50wqcNWuWpk6dqunTp6t06dLauHGjevbsqfz586tTp07Odg6Hw+V1ZpZm2eWu1WbAgAHq1auX83FsbCzhGwAAAABww9IdvEuVKqXNmzdr/Pjx8vHx0blz59SqVSt1795dd9xxx00r8OWXX1b//v3Vtm1bSdK9996rffv2acSIEerUqZPCw8MlXezVvvRzjx075uwFDw8PV0JCgk6dOuXS633s2DFFRkZe8XMDAgJu6pB5AAAAAMDtKd3BW7oYaIcOHXqzarmi8+fPK0sW1xHxPj4+zq8TK1q0qMLDw7Vo0SKVL19ekpSQkKDly5fr7bffliRVrFhRfn5+WrRokVq3bi1JOnz4sLZs2aKRI0e6tX4AAAAAwO0t3cH7k08+UY4cOfTYY4+5LP/iiy90/vx5l2Hg/0bTpk01bNgw3XnnnSpdurQ2bNig0aNH68knn5R0cYh5z549NXz4cEVERCgiIkLDhw9XtmzZ1K5dO0lSSEiIoqKi1Lt3b+XOnVuhoaHq06eP7r33Xucs5wAAAAAAuEO6g/dbb72lCRMmpFmeL18+devW7aYF7/fff1+DBg3Sc889p2PHjil//vx6+umn9dprrznb9O3bV3FxcXruued06tQpVa1aVQsXLlRQUJCzzbvvvitfX1+1bt1acXFxql27tiZPniwfH5+bUicAAAAAAFfiMDNLzwuzZs2q7du3q0iRIi7L9+7dq5IlSyouLu5m1Oc1YmNjFRISopiYGAUHB1/Xa4r0n+uWWva+1dgt7ytlzpoBAAAAIKPdSEZM99eJ5cuXT5s3b06zfNOmTcqdO3d63xYAAAAAgFtKuoN327Zt1aNHDy1btkzJyclKTk7W0qVL9eKLLzpnIAcAAAAA4HaX7nu833zzTe3bt0+1a9eWr+/Ft0lJSVHHjh01fPjwm1YgAAAAAACZWbqDt7+/v2bNmqU33nhDmzZtUmBgoO69914VLlz4ZtYHAAAAAECm9q++x1uSihUrpmLFit2MWgAAAAAAuOWkO3gnJydr8uTJWrJkiY4dO6aUlBSX55cuXfqviwMAAAAAILNLd/B+8cUXNXnyZDVu3FhlypSRw+G4mXUBAAAAAHBLSHfwnjlzpj7//HM1atToZtYDAAAAAMAtJd1fJ+bv76977rnnZtYCAAAAAMAtJ93Bu3fv3nrvvfdkZjezHgAAAAAAbinpHmq+YsUKLVu2TD/88INKly4tPz8/l+e//vrrf10cAAAAAACZXbqDd86cOdWyZcubWQsAAAAAALecdAfvTz755GbWAQAAAADALSnd93hLUlJSkhYvXqyJEyfqzJkzkqRDhw7p7NmzN6U4AAAAAAAyu3T3eO/bt08NGjTQ/v37FR8fr7p16yooKEgjR47UhQsXNGHChJtZJwAAAAAAmVK6e7xffPFFVapUSadOnVJgYKBzecuWLbVkyZKbUhwAAAAAAJndv5rVfOXKlfL393dZXrhwYf3111//ujAAAAAAAG4F6e7xTklJUXJycprlBw8eVFBQ0L8qCgAAAACAW0W6g3fdunU1ZswY52OHw6GzZ89q8ODBatSo0c2oDQAAAACATC/dQ83fffdd1apVS6VKldKFCxfUrl07/fHHH8qTJ49mzJhxM2sEAAAAACDTSnfwzp8/vzZu3KgZM2YoOjpaKSkpioqKUvv27V0mWwMAAAAA4HaW7uAtSYGBgXryySf15JNP3qx6AAAAAAC4paQ7eE+ZMuWaz3fs2DG9bw0AAAAAwC0j3cH7xRdfdHmcmJio8+fPy9/fX9myZSN4AwAAAACgfzGr+alTp1x+zp49qx07duiBBx5gcjUAAAAAAP6/dAfvK4mIiNBbb72VpjccAAAAAIDb1U0N3pLk4+OjQ4cO3ey3BQAAAAAgU0r3Pd7ffvuty2Mz0+HDhzV27FhVr179XxcGAAAAAMCtIN3Bu0WLFi6PHQ6H8ubNq4cffljvvPPOv60LAAAAAIBbQrqDd0pKys2sAwAAAACAW9JNv8cbAAAAAAD8n3T3ePfq1eu6244ePTq9HwMAAAAAQKaW7uC9YcMGRUdHKykpScWLF5ck7dy5Uz4+PqpQoYKzncPh+PdVAgAAAACQSaU7eDdt2lRBQUH69NNPlStXLknSqVOn1KVLFz344IPq3bv3TSsSAAAAAIDMKt33eL/zzjsaMWKEM3RLUq5cufTmm2/e9FnN//rrLz3xxBPKnTu3smXLpnLlymn9+vXO581MQ4YMUf78+RUYGKiaNWtq69atLu8RHx+vF154QXny5FH27NnVrFkzHTx48KbWCQAAAADA5dIdvGNjY3X06NE0y48dO6YzZ878q6IuderUKVWvXl1+fn764Ycf9Pvvv+udd95Rzpw5nW1Gjhyp0aNHa+zYsVq7dq3Cw8NVt25dlzp69uyp2bNna+bMmVqxYoXOnj2rJk2aKDk5+abVCgAAAADA5dI91Lxly5bq0qWL3nnnHd1///2SpNWrV+vll19Wq1atblqBb7/9tgoVKqRPPvnEuaxIkSLO/zczjRkzRgMHDnR+7qeffqqwsDBNnz5dTz/9tGJiYvTxxx/rs88+U506dSRJU6dOVaFChbR48WLVr1//ptULAAAAAMCl0t3jPWHCBDVu3FhPPPGEChcurMKFC6t9+/Zq2LChxo0bd9MK/Pbbb1WpUiU99thjypcvn8qXL6///e9/zuf37NmjI0eOqF69es5lAQEBqlGjhlatWiVJWr9+vRITE13a5M+fX2XKlHG2AQAAAADAHdIdvLNly6Zx48bp77//ds5wfvLkSY0bN07Zs2e/aQXu3r1b48ePV0REhBYsWKBnnnlGPXr00JQpUyRJR44ckSSFhYW5vC4sLMz53JEjR+Tv7+9yP/rlbS4XHx+v2NhYlx8AAAAAAG5UuoN3qsOHD+vw4cMqVqyYsmfPLjO7GXU5paSkqEKFCho+fLjKly+vp59+Wk899ZTGjx/v0u7yry0zs3/8KrNrtRkxYoRCQkKcP4UKFfp3KwIAAAAAuC1dd/BOSUlxefz333+rdu3aKlasmBo1aqTDhw9Lkrp27XpTv0rsjjvuUKlSpVyWlSxZUvv375ckhYeHS1Kanutjx445e8HDw8OVkJCgU6dOXbXN5QYMGKCYmBjnz4EDB27K+gAAAAAAbi/XHbxHjx6tefPmOR+/9NJL8vPz0/79+5UtWzbn8jZt2mj+/Pk3rcDq1atrx44dLst27typwoULS5KKFi2q8PBwLVq0yPl8QkKCli9frsjISElSxYoV5efn59Lm8OHD2rJli7PN5QICAhQcHOzyAwAAAADAjbruWc3r1q2rRx99VIcPH1ZUVJQWLlyoBQsWqGDBgi7tIiIitG/fvptW4EsvvaTIyEgNHz5crVu31po1a/Thhx/qww8/lHRxiHnPnj01fPhwRUREKCIiQsOHD1e2bNnUrl07SVJISIiioqLUu3dv5c6dW6GhoerTp4/uvfde5yznAAAAAAC4w3UH7/vuu09r1qxRly5dFBUVpXPnzrn0dKc6ceKEAgICblqBlStX1uzZszVgwAC9/vrrKlq0qMaMGaP27ds72/Tt21dxcXF67rnndOrUKVWtWlULFy5UUFCQs827774rX19ftW7dWnFxcapdu7YmT54sHx+fm1YrAAAAAACXc1g6Z0Nr3LixKlSooDfeeENBQUHavHmzChcurLZt2yolJUVffvnlza7Vo2JjYxUSEqKYmJjrHnZepP9ct9Sy963GbnlfKXPWDAAAAAAZ7UYy4nX3eF9u1KhRqlmzptatW6eEhAT17dtXW7du1cmTJ7Vy5cr0vi0AAAAAALeUdH+dWKlSpbR582ZVqVJFdevW1blz59SqVStt2LBBd999982sEQAAAACATCtdPd6JiYmqV6+eJk6cqKFDh97smgAAAAAAuGWkq8fbz89PW7ZskcPhuNn1AAAAAABwS0n3UPOOHTvq448/vpm1AAAAAABwy0n35GoJCQn66KOPtGjRIlWqVEnZs2d3eX706NH/ujgAAAAAADK7Gw7eu3fvVpEiRbRlyxZVqFBBkrRz506XNgxBBwAAAADgohsO3hERETp8+LCWLVsmSWrTpo3++9//Kiws7KYXBwAAAABAZnfD93ibmcvjH374QefOnbtpBQEAAAAAcCtJ9+RqqS4P4gAAAAAA4P/ccPB2OBxp7uHmnm4AAAAAAK7shu/xNjN17txZAQEBkqQLFy7omWeeSTOr+ddff31zKgQAAAAAIBO74eDdqVMnl8dPPPHETSsGAAAAAIBbzQ0H708++cQddQAAAAAAcEv615OrAQAAAACAqyN4AwAAAADgRgRvAAAAAADciOANAAAAAIAbEbwBAAAAAHAjgjcAAAAAAG5E8AYAAAAAwI0I3gAAAAAAuBHBGwAAAAAANyJ4AwAAAADgRgRvAAAAAADcyNfTBQD/VpH+c9323nvfauy29wYAAABwe6DHGwAAAAAANyJ4AwAAAADgRgRvAAAAAADciOANAAAAAIAbMbka4AFMCAcAAADcPujxBgAAAADAjQjeAAAAAAC4EcEbAAAAAAA3ynTBe8SIEXI4HOrZs6dzmZlpyJAhyp8/vwIDA1WzZk1t3brV5XXx8fF64YUXlCdPHmXPnl3NmjXTwYMHM7h6AAAAAMDtJlMF77Vr1+rDDz9U2bJlXZaPHDlSo0eP1tixY7V27VqFh4erbt26OnPmjLNNz549NXv2bM2cOVMrVqzQ2bNn1aRJEyUnJ2f0agAAAAAAbiOZJnifPXtW7du31//+9z/lypXLudzMNGbMGA0cOFCtWrVSmTJl9Omnn+r8+fOaPn26JCkmJkYff/yx3nnnHdWpU0fly5fX1KlT9dtvv2nx4sWeWiUAAAAAwG0g0wTv7t27q3HjxqpTp47L8j179ujIkSOqV6+ec1lAQIBq1KihVatWSZLWr1+vxMRElzb58+dXmTJlnG0AAAAAAHCHTPE93jNnzlR0dLTWrl2b5rkjR45IksLCwlyWh4WFad++fc42/v7+Lj3lqW1SX3+5+Ph4xcfHOx/Hxsb+q3UAAAAAANyevL7H+8CBA3rxxRc1depUZc2a9artHA6Hy2MzS7PsctdqM2LECIWEhDh/ChUqdOPFAwAAAABue14fvNevX69jx46pYsWK8vX1la+vr5YvX67//ve/8vX1dfZ0X95zfezYMedz4eHhSkhI0KlTp67a5nIDBgxQTEyM8+fAgQNuWDsAAAAAwK3O64N37dq19dtvv2njxo3On0qVKql9+/bauHGj7rrrLoWHh2vRokXO1yQkJGj58uWKjIyUJFWsWFF+fn4ubQ4fPqwtW7Y421wuICBAwcHBLj8AAAAAANwor7/HOygoSGXKlHFZlj17duXOndu5vGfPnho+fLgiIiIUERGh4cOHK1u2bGrXrp0kKSQkRFFRUerdu7dy586t0NBQ9enTR/fee2+aydoAAAAAALiZvD54X4++ffsqLi5Ozz33nE6dOqWqVatq4cKFCgoKcrZ599135evrq9atWysuLk61a9fW5MmT5ePj48HKAQAAAAC3ukwZvH/88UeXxw6HQ0OGDNGQIUOu+pqsWbPq/fff1/vvv+/e4gAAAAAAuITX3+MNAAAAAEBmRvAGAAAAAMCNCN4AAAAAALgRwRsAAAAAADcieAMAAAAA4EYEbwAAAAAA3IjgDQAAAACAGxG8AQAAAABwI4I3AAAAAABuRPAGAAAAAMCNCN4AAAAAALgRwRsAAAAAADcieAMAAAAA4EYEbwAAAAAA3IjgDQAAAACAGxG8AQAAAABwI4I3AAAAAABuRPAGAAAAAMCNCN4AAAAAALgRwRsAAAAAADcieAMAAAAA4EYEbwAAAAAA3IjgDQAAAACAGxG8AQAAAABwI4I3AAAAAABuRPAGAAAAAMCNCN4AAAAAALgRwRsAAAAAADcieAMAAAAA4EYEbwAAAAAA3IjgDQAAAACAGxG8AQAAAABwI4I3AAAAAABuRPAGAAAAAMCNCN4AAAAAALiR1wfvESNGqHLlygoKClK+fPnUokUL7dixw6WNmWnIkCHKnz+/AgMDVbNmTW3dutWlTXx8vF544QXlyZNH2bNnV7NmzXTw4MGMXBUAAAAAwG3I64P38uXL1b17d61evVqLFi1SUlKS6tWrp3PnzjnbjBw5UqNHj9bYsWO1du1ahYeHq27dujpz5oyzTc+ePTV79mzNnDlTK1as0NmzZ9WkSRMlJyd7YrUAAAAAALcJX08X8E/mz5/v8viTTz5Rvnz5tH79ej300EMyM40ZM0YDBw5Uq1atJEmffvqpwsLCNH36dD399NOKiYnRxx9/rM8++0x16tSRJE2dOlWFChXS4sWLVb9+/QxfLwAAAADA7cHre7wvFxMTI0kKDQ2VJO3Zs0dHjhxRvXr1nG0CAgJUo0YNrVq1SpK0fv16JSYmurTJnz+/ypQp42xzufj4eMXGxrr8AAAAAABwozJV8DYz9erVSw888IDKlCkjSTpy5IgkKSwszKVtWFiY87kjR47I399fuXLlumqby40YMUIhISHOn0KFCt3s1QEAAAAA3AYyVfB+/vnntXnzZs2YMSPNcw6Hw+WxmaVZdrlrtRkwYIBiYmKcPwcOHEh/4QAAAACA21amCd4vvPCCvv32Wy1btkwFCxZ0Lg8PD5ekND3Xx44dc/aCh4eHKyEhQadOnbpqm8sFBAQoODjY5QcAAAAAgBvl9cHbzPT888/r66+/1tKlS1W0aFGX54sWLarw8HAtWrTIuSwhIUHLly9XZGSkJKlixYry8/NzaXP48GFt2bLF2QYAAAAAAHfw+lnNu3fvrunTp+ubb75RUFCQs2c7JCREgYGBcjgc6tmzp4YPH66IiAhFRERo+PDhypYtm9q1a+dsGxUVpd69eyt37twKDQ1Vnz59dO+99zpnOQcAAAAAwB28PniPHz9eklSzZk2X5Z988ok6d+4sSerbt6/i4uL03HPP6dSpU6pataoWLlyooKAgZ/t3331Xvr6+at26teLi4lS7dm1NnjxZPj4+GbUqAAAAAIDbkNcHbzP7xzYOh0NDhgzRkCFDrtoma9asev/99/X+++/fxOqA20uR/nPd8r5732rslvcFAAAAvIHX3+MNAAAAAEBmRvAGAAAAAMCNCN4AAAAAALgRwRsAAAAAADcieAMAAAAA4EYEbwAAAAAA3Mjrv04MAP4NvgINAAAAnkaPNwAAAAAAbkTwBgAAAADAjQjeAAAAAAC4EcEbAAAAAAA3IngDAAAAAOBGBG8AAAAAANyI4A0AAAAAgBsRvAEAAAAAcCOCNwAAAAAAbuTr6QIAAK6K9J/rtvfe+1Zjt703AAAArowebwAAAAAA3IjgDQAAAACAGxG8AQAAAABwI4I3AAAAAABuRPAGAAAAAMCNCN4AAAAAALgRXycGAPjX+Ao0AACAq6PHGwAAAAAANyJ4AwAAAADgRgRvAAAAAADciOANAAAAAIAbMbkaAOC2xIRwAAAgo9DjDQAAAACAGxG8AQAAAABwI4aaAwCQibhriLw7h8dnxmH91OwqM+4fmbFmif0DuFXR4w0AAAAAgBvR4w0AAADA62TWXnpGcfyfzFiz5J66b7se73Hjxqlo0aLKmjWrKlasqJ9//tnTJQEAAAAAbmG3VfCeNWuWevbsqYEDB2rDhg168MEH1bBhQ+3fv9/TpQEAAAAAblG3VfAePXq0oqKi1LVrV5UsWVJjxoxRoUKFNH78eE+XBgAAAAC4Rd0293gnJCRo/fr16t+/v8vyevXqadWqVWnax8fHKz4+3vk4JiZGkhQbG3vdn5kSfz6d1V7bjdRwo6jZlbvqzow1S+wfl8qMNUvs05fKjDVL7NOXY//4P5mxZol9+nLsH/8nM9YssU9fKjPWLF1/3antzOwf2zrselrdAg4dOqQCBQpo5cqVioyMdC4fPny4Pv30U+3YscOl/ZAhQzR06NCMLhMAAAAAkIkcOHBABQsWvGab26bHO5XD4XB5bGZplknSgAED1KtXL+fjlJQUnTx5Urlz575i+38jNjZWhQoV0oEDBxQcHHxT39tdqDnjZMa6qTljZMaapcxZNzVnDGrOOJmxbmrOGJmxZilz1k3NGcOdNZuZzpw5o/z58/9j29smeOfJk0c+Pj46cuSIy/Jjx44pLCwsTfuAgAAFBAS4LMuZM6c7S1RwcHCm2YFTUXPGyYx1U3PGyIw1S5mzbmrOGNSccTJj3dScMTJjzVLmrJuaM4a7ag4JCbmudrfN5Gr+/v6qWLGiFi1a5LJ80aJFLkPPAQAAAAC4mW6bHm9J6tWrlzp06KBKlSqpWrVq+vDDD7V//34988wzni4NAAAAAHCLuq2Cd5s2bfT333/r9ddf1+HDh1WmTBnNmzdPhQsX9mhdAQEBGjx4cJqh7d6MmjNOZqybmjNGZqxZypx1U3PGoOaMkxnrpuaMkRlrljJn3dScMbyl5ttmVnMAAAAAADzhtrnHGwAAAAAATyB4AwAAAADgRgRvAAAAAADciOANAAAAAIAbEbwBAADglZgDGPBO8fHxkqSUlBQPV5J5ELwB3Pb27dvHyR1uGZs2bdLKlSs9XQbwr/3444+Ki4vzdBm3lb179+rbb7/1dBnwcps3b1azZs106NAhZcmS+eKkp875Mt+WukVx0p/xuELnXplln46Pj1fbtm111113ZZqagatZunSpGjdurNDQUE+Xctu69DiSnJzswUoyv48++kjLli1zWcZx2n0OHTqkypUrq3///po2bZqny4EXW758uRYtWqRz5845l2WG8+rUGh0Oh3788Ud99913Gfr5BG8PO3nypM6fPy+Hw+HpUv61zPDHcNu2bVqxYoX27dvn9VfoduzYoXXr1mnFihWeLuWG7Nq1S8ePH1dSUpKnS7ku/v7+GjVqlHLkyKGKFStmiv34VnC17cz2T79ly5apVatWmjVrlkqWLOnpctLt0pO3zHAidykzk8Ph0IkTJ3T8+HH5+Pho7ty52rRpk6dLu6IrbV9vuFiQkpIiM1NcXJz8/f0lZe7zJW/dzpfbsWOH/v77b+XIkUNffvmlPv30U0+X9K9ktuPH1er1xr+LpUqVUr9+/RQREaEff/xRe/bsUZYsWbx2m69Zs0aSlCVLFiUkJOjs2bOKiorK8N9D704et7g5c+aoWbNmKl++vIYOHaoNGzZ4uqTrknoAiI6O1hdffKFx48bp2LFjXv/HcM6cOapcubK6dOmi4sWL68MPP9SZM2c8XdYVzZkzRw0aNFDHjh1Vr149RUVF6fDhw54u6x8NHDhQzZs3V8mSJfXqq69q3bp1ni7pHzkcDkVGRup///uf4uLiMkX4Tq0vKSkpzTBMb69d+r9w8vPPP2vUqFHq0aOHvv32W8XGxsrhcGSKdfj666/1ySefaNq0aTp9+rSny9H58+e1ZMkSzZ07V9WrV1d0dLQmTZqkGTNmaOPGjc523r5tzcx5UXTixIl68sknNXz48Ezz99HhcOjYsWNq3bq1xo8fr0mTJqlp06batWuXp0tLIyUlxbmtV69ereXLl+vvv/+Wj4+Phyu7eHLscDgUERGhAgUK6LvvvsuU50uSd2/ny9WqVUtdunRRQkKCfHx8NGXKFE2dOtXTZaXLxIkTFRUVpREjRrgcA73VpfvJ3LlzNXv2bP3000+SLh5XvC3Q+vn5qXz58kpJSdGwYcNUpUoV7d271yvD97Jly9SkSRONGjVK0sUOl8DAQPn7+2f86DCDR6xfv95CQkLs9ddftxdffNEqVKhgjzzyiP3888+eLu26fPnll1agQAGrVq2aVatWzYKDg+2LL76whIQET5eWRkpKip08edKqV69uEydOtD/++MOGDRtmDofDhg8fbqdPn/Z0iS4WLFhgOXPmtIkTJ1p8fLzNmzfPHA6HtW3b1g4cOODp8q7q888/twIFCthXX31lQ4YMsapVq1qrVq28cp8+fPiw/fLLLy7LEhIS7Ndff7WIiAgrX768paSkeKi6a0uta+7cuda2bVsrWbKk9e3b177++msPV3ZjvvrqKwsKCrKuXbtaw4YNrUqVKta8eXO7cOGCp0v7R71797agoCArV66cBQQE2IMPPmizZs3y+D5z/vx5M7t4fM6bN69FRkZamTJl7MEHH7Tp06c723m6zqu5tK6hQ4dacHCwtW7d2vLly2cNGza0WbNmebC6f3b06FHn/w8cONDuvvtu8/HxsbFjx5qZWXJysqdKu6Z+/fpZzpw57Y477rC8efPavHnzPF5r6r6QmJhof/75Z6Y+X0rljdv5UqnH3rlz51rnzp1twYIF1qpVK3vooYds6tSpHq7uxqQePx577LFMcfy49NjXq1cvy5s3r+XLl8/KlCljvXr1cj7nLfvL5X9DVq5caY0aNbIiRYrYn3/+aWbeU6uZ2Y4dO6xPnz5WunRp+89//uNcXqpUKdu4caOZmSUlJWVIzQRvD9i1a5e98cYb9uabbzqXff/991arVi1r0aKF1/8xWbduneXJk8cmTZpkZmbHjh0zh8NhI0eOdLbxphO7uLg4O3/+vL3yyit28uRJ5/L33nvPGb5jYmI8WOH/iYmJsW7dutnQoUPNzGz37t12991326OPPmo5c+a05s2b2759+zxcZVrLly+3Hj162Mcff+xc9t1333nlPr1//37LnTu3ORwOq1mzpg0YMMCWLFlisbGxZma2Zs0aq1ChgpUtW9ar9mOz//u9+uabbyxbtmw2aNAg++yzz6xmzZoWERFh69ev93CF12fXrl1WrFgxmzBhgpmZ7d2713LkyGF9+/Z1aedt29/MbN++fVauXDlbu3atnT9/3o4ePWoNGjSwGjVq2Ny5cz1S06UnCz/++KPly5fPxo0bZ2ZmCxcutKCgICtSpIj973//c7bztm176TpER0dbp06dnMeN3377zZo3b24PP/ywzZgxw1MlXtOgQYOsd+/ezuPIhg0bLFeuXFaoUCEbNmyYHTt2zMy842T00n/7n376yUqUKGE//vijbdiwwZ555hkLDAy0GTNmWFJSksdr3LVrl73++uv2+uuvO5/LLOdLl/5be+t23r9/v82ePdtl2bFjx6xEiRI2duxYO3bsmLVq1cpq1qyZacJ3Zjx+pNq5c6dVr17dNm7caFu3brXRo0fbPffcY926dXO28fQxJPXz4+Li7OzZs87l69ats7p163pV+J4zZ47Fx8eb2cXzjH79+lnx4sVt1KhRlpiYaEWKFLENGzZkaE0E7wwWExNjlSpVsnz58ln//v1dnvvuu++sZs2a9uijj9rSpUs9VOE/mzNnjrVs2dLMLh4k7rzzTpeDQupVU284sZszZ47Vr1/fSpYsaSVKlLBNmza5PP/ee++Zn5+fDRo0yCvCd3x8vH3xxRe2a9cu+/vvv618+fIWFRVlZmYzZswwh8NhjRo1soMHD3q40v9z+PBhu/vuuy04ONjeffddl+dS92lvOkHau3evlStXzooXL26VKlWyTp06WdasWa1cuXL2xBNP2KxZs+zzzz+3YsWK2cMPP+zx/Xju3LnO/TY5OdmOHz9utWrVstGjR5vZxV7OvHnz2ksvveTJMq9pz5499s033zgfr1q1ysqUKWNmFy8u3XnnnfbUU0+5PO+No2eGDx9uzZo1s9atW1tcXJxz3zh69KhVq1bNmjZt6tH64uLirH///vbcc8+Z2cWLBEWLFrXHHnvMOnToYAULFnTp+fYGmzdvdjk5mzJlij300EN2//33O8OqmdmmTZu89uS5b9++ljNnTlu1apWZmZ0+fdpOnz5ta9asscGDB1v58uXt1Vdfda5PRh9TEhMTnbVd6v3337cRI0bYa6+95rK8R48eljVrVo+HwlvhfMnMe7fzpRehGzVqZLNmzbIdO3aYmdm3335rDz74oB07dsx+//13a9WqldWpU8c++uijDK/zRmSG40dSUpJ9/vnnaULpxx9/bA0bNrTOnTs794fTp0/b+PHj7e677/Zo+F66dKnL3+RvvvnG6tata5GRkTZs2DDnMS06OtoZvnfv3u2RWlP169fP7rnnHudFALOL5yL9+vWzEiVK2Msvv2xlypSxDh06WP/+/a13797Wr18/e+mll5znV+5A8PaA6OhoK1asmFWvXt22bNni8tzcuXOtfPny1r59e+ewQW8zYsQIq1atmh0+fNgKFy5s3bp1c/5iff7559a9e3dLTEz0cJVma9euteDgYHv22Wetc+fO5ufnZy+++KLt3bvXpd1bb71luXLlshMnTnioUldxcXFmZjZt2jSrVq2ac3j5jBkzrGbNmla4cGGv6/XetGmTFStWzOrWrWubN292ee7777+3mjVrWsuWLW316tUeqtDVH3/8YS1btrTmzZvb6tWrbd++fTZjxgyrXr26ValSxQIDA61MmTLmcDicF5k84ciRI1a0aFHr0qWL/f7772Zmdu7cOStfvrzt2LHDdu/ebQUKFHAJrYsWLbJdu3Z5quQ0/vrrL8uTJ4+VLFnSPvvsMzO7OCwtMjLStm3bZoUKFbKnnnrKeaKxbt06e+mll2znzp2eLDuN5ORke++99yxbtmwWERHh7NlMPRn5+eefzd/fP80x3Z32799vX3zxhZmZTZ8+3Xr06GH79++3FStW2NmzZ61KlSr25JNPmtnFUSnZsmWzoKAgl5EpnvTKK69Yly5dXG4vWLhwoVWqVMly5sxpc+bMcWm/efNm58nzzJkzM7rcK5oyZYrlzZvXeWFx7ty51qJFC9u6dauzzYABA6x8+fI2ePBgZxj473//m+ZCsLts377dOnfubDExMS4nwfXr13fexnT5xQBPh8JUme18qU6dOvbtt9+6LPPW7bx3716rVKmSVatWzSpWrGhdu3a1woUL24QJE2zWrFnWpEkTmzdvnpmZbd261erUqWNNmzb1ik6Kq8kMx4/du3c7L96mOnPmjL388stWqFAhe+CBB1zanz592iZMmGD33HOPy9/6jLqA9/vvv5vD4bA+ffqY2cW/JcHBwfbcc89Z9+7dLWvWrPbEE084R5RGR0dbw4YNLTg42Pbs2ZMhNV6uR48eFhYWZitWrEjz3J9//ukM5T4+Pvbss89aq1atrEmTJtayZUtr2LChW/+OE7w9ZNOmTVauXDnr1q1bmn/gBQsWpAmHnnDpQeFSmzZtsmrVqllQUJDzpC71j3mfPn2sefPmHr9veteuXfbaa6/ZiBEjnMvGjRtnBQsWtP79+6fZvpcOQfcWb775ppUpU8ZZW//+/e3999/3yp5AM7ONGzda+fLl7amnnrriCdKDDz5oTz/9tJ05c8bjvchmF09G69evb3Xr1rU1a9Y4l586dcqmTJliAwcOtAoVKlh0dLQHq7w4H0TlypWta9eutnnzZjt79qzdfffdzj/EXbt2dZ6w7d2719q1a+c8WfIGS5cuNYfDYZUrV7bmzZvb9OnT7cKFC1aoUCFzOBz2/PPPu7Tv1auX1ahRw44fP+6hiq8uNjbWPvnkE/P397cBAwa4PPfjjz/aXXfdlWEXPRISEqxt27YWGRlpL730kjkcDvvwww+dz//8889WoUIFZz0bN260Bg0a2GuvvebSA+ApAwYMsIoVK7rcF51qxYoVVq1aNWvSpIktXrzY5blNmzZZy5YtrUGDBrZ8+fKMKveqVq5cadu2bTMzsy+++MICAwNt9OjR9tdff7m0GzBggFWuXNlat25tzz77rDkcDvvtt98ypMbVq1fbQw895Hyc+jclISHBnnzySQsODrZly5aleV2PHj0sMDDQOVrFUz1XmeF8ycysYcOGVqZMGeex6++//zYz797OO3futFatWlmLFi3s66+/tjlz5jhHqTkcDqtSpYpzqO727du9ep6ZVN5+/Lhw4YJVqVIlzXny/v37bejQoRYSEmKvvvqqy3MxMTE2fvx4K1asmL3wwgsZWa6ZXez4yZo1qw0aNMimTp1qo0aNcj63cuVKy5Ejhz3++OPOY8uaNWusVatW9scff2R4rXv27LGHH37YfvzxRzMz27Jli82fP98+/vhj5/576NAh69+/v5UtW9bGjx/v8np3n58SvD0oOjraKlSoYF27dnW5Ou4NDh48aI899pjLEK7UnTH1PuS77rrLhg8fbmYXd/RXXnnFcufOnaE9PleSOjwtT5489sorr7g8N3bsWCtQoIANHDjQOQzGzDuGxV9uw4YNFhAQYNWrV7fatWtbcHBwhvWQpFfqPv3UU0+l2ac/+OADu+eee1yGf3nazp07rX79+la/fn3nQfpS3jByw+z/tmtUVJQdOnTI3n33XefwwEu98sorVrp0adu/f7+HKr2yJ5980u677z575JFH7KGHHrLvv//eVq5caYUKFbI2bdrY+vXrbeXKlda7d28LCQlJM2rCk06dOmWnTp1yPj5//ryNHz/efHx8rGfPnrZixQrbsmWLNWzY0O6///4MPWk+deqUVa1a1RwOhz377LMuzy1btsxCQkKcJ/MDBgywxx9/3GVdPGXZsmXWoEEDZ0BZu3atLVy40BYsWOC84Pvjjz9aZGSktWjRwpYsWeLy+o0bN1pERITLPCmetmnTJitQoIBz3oLY2Fg7d+6cS5v//Oc/1qZNG6tRo0aGHsv3799v7du3t9jYWBs1apS1atXKtm/fbmYXQ94jjzxiefLkueLtQM8995xlz57dDh06lGH1Xok3ny+ZmTVr1swqV65sR44cMTOzd955x1q2bJkptvP27dutYcOGVq9ePduxY4edPXvWfvnlF2vSpIlNmTLFzLzzHCnVunXrMs3xIzk52fbv32+1atUyM7MTJ07Y8ePHnceK48eP2+DBg61EiRI2ePBgl9fGxMTY+++/b8WLF7eFCxdmdOk2Y8YM8/X1tVy5cqXZdqtWrbLs2bNbhw4dnBecPDVRamJiovOixpdffmkFCxa0YsWK2R133GEhISH2/vvv27lz5+zgwYPWt29fK1mypMttIATvW1x0dLRVqVLF2rZt67xq7g3+/PNPq1atmjVu3NhlqEZqz9rRo0ctKirKSpQoYdmzZ7dKlSrZ3Xff7fHewVTR0dEWERFh1atXT9OrMH78eMuaNasNHTrUa4LV1axatcqeeOIJ6969u8cvaFyv6Ohoq1y5sj366KO2e/du50Fs0KBBVqJECa8K3mYXw3eDBg2sfv36tnLlSk+Xc1XR0dFWrlw569q1q82dO9d69uxpPj4+NnLkSBs5cqQ9++yzFhQUlOEThVzLtWbJ/fjjj+3nn3+2e+65x/Lnz2/Fixe3qlWrelX9b7/9tkVGRlr58uWtWbNmzpOjhIQEGz9+vAUGBprD4bCXXnrJZUb2jArfCQkJ9vDDD1u5cuWsbt26LpMf/fHHH9a2bVsLDw+38uXLW1BQkHP2Vk87fvy4c1v179/fihUrZnnz5rVChQpZ0aJFnZMELl261B544AF75JFHnKM4Uo8nrVq1sg4dOnh0GPSl9Xz11VdWsmRJi4mJsX379ln16tWdk+1deiIXHx+fJpC727lz55zH3Xnz5jlHq6Xez5ucnGytWrWyvHnzOv/ep+7Dhw8ftlKlStn8+fMztOYr8dbzJbOLt1Rd+rfthx9+yFTbeefOnVavXj2rV6/eFYfneqvU40e+fPkyxfHj0r8NH3/8sVWtWtXuvPNOu+uuu2zy5Ml29uxZO3nypA0ePNhKlizpnGg31aFDh6xEiRL21VdfZUi9qdsrte6vv/7aAgMDrV27ds7bO1Lb/PLLL+ZwOKxr164en1TN7OJtd1mzZrWJEyfa3r17LT4+3nr16mW5cuVy9nL/+eef9vzzz1vlypWdFwzcjeDtBdasWWM1atTw+BXly10aSC49EKcOdT5z5owdP37c3n77bdu6dWuaoXWedq3haR999JHX3UN6NcnJyV59tflKfv31V+vSpYvLwdrPz8/Wrl3r4cqubOfOndakSRO7//7703zNmDeJjo62SpUq2dNPP22LFi2y999/30qXLm1Vq1a1xx9/PMOGrl7LP82Se/ToUecsuXPnzrXExETbunWrbd++3atu+XjllVfsjjvusA8++MDmz59vYWFh9vDDDzuPGxcuXLBJkyZZtmzZXK6Wpw7LzCgXLlyww4cPW+PGja1WrVou4Xv79u320Ucf2YgRI7zmeHfpie6bb75puXLlskWLFtnOnTud9wbmy5fPOURx6dKlVqxYMZfJtd544w1zOBxecTEyddj++vXrLV++fFanTh3LlSuXtW7d2rmuv/zyS5rfiYxweahIPR4vXbrUQkNDrVOnTi6h8NFHHzWHw+HSGz9w4EALDQ31miHG3ni+dHnISP17ndm286XnfN4yGeq1DBs2zEJDQ23x4sWZ7vjx8ssvW+7cuW3ixIk2a9Yse/755y1Hjhz22muvWUpKih06dMiGDh1qoaGhLnNyvPrqq5Y7d+4MuaUpdT/+9ddf7auvvrIzZ86Y2cVbanx9fa1fv37OPJDads2aNR69KJZax4kTJ+ydd95x+TaEVC+++KKFhoY6b3Pav3//FW95cheCt5e42v3Unna18J2UlGTx8fHWr18/a9Gihdd+9663D0+7lV16sWDDhg1ecx/e1Wzbts0effRRr5u47nLr16+3SpUqWdeuXe3QoUPO7ewNx5AbnSW3Vq1aNnnyZA9XndaCBQvs3nvvtZ9++snM/q+XMCwszEqXLu08qYuLi7Nx48aZj4+PDRs2zJMl259//mmNGze22rVr26effmpmZq+99pr17NnTo3Vd6tKAsmjRIouKirLvvvvOpc2pU6fsgQcesBo1ajhHJG3YsMEZIk+ePGmvvfaaV4yu2rNnj9133302e/ZsS05OtsWLF9usWbOsePHiLhfBevbsadWqVcuwSanGjRvnMrph8eLFaUYaLVmyxEJCQuyJJ55wXpRJTk62V155xbmtly5damFhYbZu3boMqft6ecOxzuzK2/nyE/jMtp0zy0XozHz8WLVqlZUrVy7N/f4jR460gIAAW7RokZld/FaKjz/+2GUOl7vuuitDJqm9dCRP7ty57c0333TeNmH2f8PO+/Xr59zOnu4gSv38xYsXW9++fe3DDz90ueCcepHgxIkTljt37gwbNXA5gjf+0ZXCd3x8vD3//PPm4+PjFSdA1+LNw9NudZ4+EN+ojO6tTK/U4fxt2rRxXrX3hm2d3llyPT0Z4+V++eUX5+Qx8+fPt9y5c9uECRNs7969ljdvXqtdu7Zzlvn4+HibOHGiORwOlwlnPGH37t3WsmVLK1OmjFWqVMmCg4O95uT50tD99ttvW4kSJeztt9++4oWuDz74wIoXL54mxKS+h7f8nv7555/WrFkze+GFF1y+27ZKlSo2dOhQ+/33361fv36WM2fODLune/fu3VawYEHr1q2bbd682Q4ePGgOh8N69uyZ5ps7Fi5caD4+Pta9e/erzqvgTT3L3uRW3s7efhE6sx0/Lj32paSk2P79+23SpEnOHuRLn2/QoIE1b948zXukhu/U12SEJUuWWFBQkE2cONHltszUADt16lQLDAz0mm8yMrt4oSBr1qw2fPhwl9vWLj0/2rp1q0VERHjsW3YI3rgul4bvZcuWWd++fS0wMNDrQ3cqbxyeBvwb3rpPZ+ZZcqdPn+6cHOvEiRN27tw5q127tg0aNMjMLvaWVK5c2RwOhz3++OPO18XHx9ukSZOcYdyTDh48aB9//LENHTrUpYfCky4d8vzCCy+Yw+Gw7NmzpxnOmnpyNHnyZKtcubJXTAR3qdT69u7d6zz5/O677ywgIMA5id358+dt0KBBFhERYffcc4+VK1cuw+ctSL0lJSoqys6fP2/ff/+9+fj4WO/evV2+LeDs2bMWERFhDocjzYgNb7hH09vdytvZWy5uXS6zHT8u/ff97LPPbObMmZaYmGhnz551aZeSkmLJycn22GOPWZcuXTxWY6rExETr0aOH8+9cbGysrVq1yp5//nnr0qWLsxPrk08+sbx582boUO2r2b59uxUtWtTGjRvnsvzyCx+vvPKKlShRwg4fPpzRJZoZwRs3IHUIUq5cuczf3985gUVm4S3D04CbxVv36cw4S+6WLVusfPnyVqFCBZsxY4aZXRy2ePfdd9v3339vZhd7Gzp27Gjbtm3z2hNmb5Y6a/3OnTutdu3aznsXLw3mFy5csDp16lzxO4+9wfLly83Hx8datGjhPHEbPHiwFS1a1HkyGhMTY9u2bbPo6GiPTSYZHR1t9913nz355JN25swZmzdvnjkcDuvdu7ezplOnTlnfvn1t0aJFHp+kLrNiO2eczHb8uPTzX375Zbvjjjts0qRJLhfLL6/9wQcfdM4ZkpH179+/37744gszM5s2bZp169bN+vTpYzVq1LCvv/7a2rVrZw0bNrRKlSpZ7dq1LSIiwjknS2xsbIbVeS0LFy60iIgIl9saL92Gmzdvth49elhwcLBHOw0J3rgh27dvt2bNmnnFpDYAvFdmmiW3T58+9sgjj1hkZKTlypXLihcvbpMnT7bk5GSrWLGiPfjggzZ16lSrVauWVa1a1Rm6OYm+fv369TOHw+G8J7ZSpUrO3r/k5GRLTEy0r776ypo0aWIlS5ZMM2mPt9ixY4fly5fPsmXLZuXLl3dOjtSlSxcbOHBght3HfT1Svwnh0lDo7+9vbdu2tWHDhlmDBg2sevXqzm3sLcNFMxu2s/tltuPHpRdm3333XQsPD7dff/3VpU3qhfOzZ8/ahg0brF69enbvvfdm+P6RkJBgbdu2tcjISHvppZfM4XDYtGnTbMGCBVavXj0LDQ219u3b2/fff28pKSn2+eef2wMPPOA1gTvV7NmzrVChQs7gfem/wc8//2wTJ060//73vx6/5TSLgBtQvHhxffnllypdurSnSwHgxSIiIjR27FhlyZJFb7zxhlasWOHpkq5o8uTJ+uijj/TKK6/o+++/1++//67ChQvrgw8+0JdffqmPPvpI8fHxGjlypHx9ffXzzz8rS5YsSklJkY+Pj6fLzzTq1KmjzZs367777pMk3XnnnTp//rwkKUuWLPL19dX69etVvXp1bd68WX5+fkpKSpLD4fBk2TIzl/9GRESod+/e6tevn5o2bar169dr0qRJWrt2rdasWaOjR496slwX5cuX16RJkxQdHa0XX3xRDzzwgJYsWaJjx45p9uzZ8vHx0bJly+RwOGRm8vX19XTJmRLb2f0y0/HDzJQly8V4FRcXp19//VUdO3ZUlSpV9Oeff+rLL79Uw4YN9eijj2rHjh1KSUnRt99+q+zZs2v9+vXy9fVVcnJyhtXr5+en8ePHKzk5WWPGjNHTTz+tdu3aqV69epo0aZJWr16tqVOnqlGjRnI4HFq7dq2yZMniPCZ6i/vuu08nTpzQhx9+KEnOfwNJmjNnjo4ePaonn3xSJUqU8FSJkiSHeduWAwDcMv744w/16tVLJ06c0Lvvvqv777/f0yW5ePXVV7V8+XItX75c0sU/1n/99ZdatWqlU6dOadiwYWrZsqXOnDmj4OBg+fj4KCkpiZPndEpOTpaPj4+ef/55HTt2TJ9//rmSkpL06KOPKkuWLPryyy+VJUsWZztPMjM5HA799NNPevbZZzV27FhVqVJFe/bs0TPPPKPBgweratWq+uabb9SvXz8dOXJEjz/+uKZNm+bRui+3YcMGPfnkk6pYsaKGDRumsLAwnT9/XoGBgXI4HOzPNwnb2f28/fixbNkyHTp0SO3bt1e3bt2UJUsWXbhwQcePH1eNGjW0cOFCBQQEKDg4WCdOnNCZM2e0cuVKHTt2TOHh4R7bTxITE9WgQQOdPHlSefPmVYcOHdShQweXNhs3btTkyZM1efJk/fTTTypbtmyG1ng9Jk2apGeeeUY9e/ZUx44d5ePjo8mTJ2vixIlavXq1x0O3JDHUHADgVt44S27qEMTXX3/dKlWq5Bz2lzpEcdmyZZYtWzarWbOm8943M++dDCmzefnll+2hhx4yM7PGjRvbXXfd5dz23rSNv/vuOxs0aJA1bdrUSpcubVFRUbZr1y6bOXOm5cmTx7lP79ixw5577jmv/drK6Ohoq1ixoj3yyCMu3wHsTdv6VsB2zhjedvxISUmx2NhYq1u3rtWoUcOaNm1qwcHBtnv3bvv+++/tkUcesQIFCtiwYcNs7dq1ZmY2ZswYa9asmctweE/eWnPhwgU7fPiwNW7c2GrVqmVTp051Prdz507r1q2bPfzwwy5foedtkpOT7fPPP7dcuXJZwYIF7Z577rHixYt71UTQ9HgDANwuISFB/v7+ni4jjd9++03ly5fXoEGDNHjwYOfyBQsW6H//+59OnTqlLFmyaO7cuV5Zf2Zj/78XecaMGRo/frx8fX114MAB/f77787hoZ7qFZw3b54KFiyosmXLOuts06aNHnzwQT3//POaMmWKFi5cqO+//14jRozQDz/8oIiICA0ZMkRBQUFe0Ut/LWvWrNGECRP00UcfuQzDxM3FdnYfbz5+SNLJkycVGRmpnTt3atiwYRowYIAk6fTp00pKSlKePHmcbRs1aqQ8efJoypQpnir3inbv3q0ePXrowoUL6ty5s5544gm9/fbb+vnnnzVlyhSFhoZ6usR/dOjQIe3bt08Oh0NFixZVWFiYp0tyIngDAG5rkydPVrdu3fTSSy+pdevWypUrl3r06KHIyEi1bNlSpUuX1sKFC1WnTh1Pl3rLWLBggRo2bKjSpUsrOjra4yfNR48eVbVq1VSzZk316dNHpUqVkiTVrFlTDRo0UP/+/SVdPLH+6quvNHDgQDkcDiUnJ2vhwoWqUKGCR+q+UanBJSUlhVDoRmxn9/K240eq06dPq3379jp79qwCAgLSDNmOjY3VmjVr9NZbb+nYsWOKjo6Wr6+vc3/xFnv27FHv3r31xx9/KCAgQLt27dKCBQtUtWpVT5eW6RG8AQC3NTPTV199pe7du8vf319mpnz58mnVqlU6evSo6tatqy+//NIr72nLrM6dO6epU6cqKipKvr6+XnHSHB0drWeeeUb33XefXnzxRZUpU0YNGzZUu3bt1KFDB5caN2/erA8//FDz5s3T0qVLVaRIEY/WfiO87ST/VsV2dh9vPH5c6siRI4qKilJcXJyioqLUvn17SRdHQ0yaNElxcXH66KOPvOaCwZX89ddfWrBggQ4ePKg2bdqoePHini7plkDwBgBAF080Dhw4oMTERFWvXl1ZsmTRgAEDNGfOHC1btkzh4eGeLvGW5E0nnhs2bFDXrl1Vrlw5vfTSSxo2bJiioqKuOtohNjZWwcHBGVwlgFTedPy41J49e/TCCy8oISFB7dq1U8eOHdW8eXPdcccdmjhxIhPu3aYI3gAAXGbr1q16++23NW/ePC1evFjlypXzdEnIIBs2bFC3bt1UunRpffXVV8qXL5/uuusu59DypKQkFS1aVBMmTFDWrFk9XS4AL7Vnzx716dNH27ZtU1xcnIKCgrRu3TrnyCpGRNx+CN4AAFwiKSlJv/32m6ZNm6YuXbqodOnSni4JGSw6OlqdO3eWj4+PSpUqpfr16+v06dM6efKksmbNqqZNm7JfAPhHhw8f1vr163X06FF16tTJK4fGI+MQvAEAuILExET5+fl5ugx4yMaNG9WtWzfdd999evXVV1W4cGFPlwQgk/P2bz+AexG8AQAArmDDhg165plnVLRoUQ0ePFglS5b0dEkAgEyK7zgAAAC4gvLly2vs2LE6cuSIcubM6elyAACZGD3eAAAA13DhwgUmUgMA/CsEbwAAAAAA3Iih5gAAAAAAuBHBGwAAAAAANyJ4AwAAAADgRgRvAAAAAADciOANAAAAAIAbEbwBAAAAAHAjgjcAAAAAAG5E8AYAAAAAwI0I3gAAAAAAuBHBGwAAAAAAN/p/7cVjThkNIp0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(syllabe_counts.head(20))\n",
    "\n",
    "syllabe_counts.head(20).plot(kind='bar', figsize=(10, 4), title='Top 20 syllabes les plus fréquentes')\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48f86d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution nettoyée des tons dans Tone 1 :\n",
      "bas   : 2651\n",
      "haut  : 1111\n",
      "moyen : 0\n",
      "\n",
      "Distribution nettoyée des tons dans Tone 2 :\n",
      "bas   : 1287\n",
      "haut  : 990\n",
      "moyen : 1485\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def normalize_tone(t):\n",
    "    if isinstance(t, str):\n",
    "        return t.strip().lower()\n",
    "    return t\n",
    "\n",
    "# Normalisation des deux colonnes\n",
    "df['Tone 1 norm'] = df['Tone 1'].apply(normalize_tone)\n",
    "df['Tone 2 norm'] = df['Tone 2'].apply(normalize_tone)\n",
    "\n",
    "# Comptage par colonne\n",
    "tone1_dist = Counter(df['Tone 1 norm'])\n",
    "tone2_dist = Counter(df['Tone 2 norm'])\n",
    "\n",
    "# Affichage des distributions\n",
    "print(\"Distribution nettoyée des tons dans Tone 1 :\")\n",
    "for k in ['bas', 'haut', 'moyen']:\n",
    "    print(f\"{k:<6}: {tone1_dist.get(k, 0)}\")\n",
    "\n",
    "print(\"\\nDistribution nettoyée des tons dans Tone 2 :\")\n",
    "for k in ['bas', 'haut', 'moyen']:\n",
    "    print(f\"{k:<6}: {tone2_dist.get(k, 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b781383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution nettoyée des tons dans Tone 1 :\n",
      "bas   : 2651\n",
      "haut  : 1111\n",
      "moyen : 0\n",
      "\n",
      "Distribution nettoyée des tons dans Tone 2 :\n",
      "bas   : 1287\n",
      "haut  : 990\n",
      "moyen : 1485\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fonction de normalisation des tons\n",
    "def normalize_tone(t):\n",
    "    if isinstance(t, str):\n",
    "        return t.strip().lower()\n",
    "    return t\n",
    "\n",
    "# Normalisation des deux colonnes\n",
    "df['Tone 1 norm'] = df['Tone 1'].apply(normalize_tone)\n",
    "df['Tone 2 norm'] = df['Tone 2'].apply(normalize_tone)\n",
    "\n",
    "# Comptage par colonne\n",
    "tone1_dist = Counter(df['Tone 1 norm'])\n",
    "tone2_dist = Counter(df['Tone 2 norm'])\n",
    "\n",
    "# Affichage texte\n",
    "print(\"Distribution nettoyée des tons dans Tone 1 :\")\n",
    "for k in ['bas', 'haut', 'moyen']:\n",
    "    print(f\"{k:<6}: {tone1_dist.get(k, 0)}\")\n",
    "\n",
    "print(\"\\nDistribution nettoyée des tons dans Tone 2 :\")\n",
    "for k in ['bas', 'haut', 'moyen']:\n",
    "    print(f\"{k:<6}: {tone2_dist.get(k, 0)}\")\n",
    "\n",
    "# Affichage graphique\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(['bas', 'haut', 'moyen'], [tone1_dist.get(k, 0) for k in ['bas', 'haut', 'moyen']])\n",
    "plt.title(\"Tone 1\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(['bas', 'haut', 'moyen'], [tone2_dist.get(k, 0) for k in ['bas', 'haut', 'moyen']])\n",
    "plt.title(\"Tone 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0bb85b",
   "metadata": {},
   "source": [
    "## 1.3 Ponderation des classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8477882",
   "metadata": {},
   "source": [
    "syll_imbalance_ratio = syllabe_counts.max() / syllabe_counts.min()\n",
    "tone_imbalance_ratio = tone_counts.max() / tone_counts.min()\n",
    "\n",
    "print(f\"Déséquilibre syllabes : {syll_imbalance_ratio:.2f}\")\n",
    "print(f\"Déséquilibre tons : {tone_imbalance_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a370dcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WordId', 'Yemba', 'Speaker', 'GroupeId', 'Statement', 'Syllabe 1',\n",
      "       'Tone 1', 'Syllabe 2', 'Tone 2', 'audio_path', 'syllable_transcript',\n",
      "       'Tone 1 norm', 'Tone 2 norm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41589e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# --- 1. Syllabe 1 ---\n",
    "syll1_classes = sorted(df['Syllabe 1'].dropna().unique())\n",
    "syll1_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=syll1_classes,\n",
    "                                     y=df['Syllabe 1'].dropna())\n",
    "syll1_weights_tensor = torch.tensor(syll1_weights, dtype=torch.float32)\n",
    "\n",
    "# --- 2. Tone 1 norm ---\n",
    "tone1_classes = sorted(df['Tone 1 norm'].dropna().unique())\n",
    "tone1_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=tone1_classes,\n",
    "                                     y=df['Tone 1 norm'].dropna())\n",
    "tone1_weights_tensor = torch.tensor(tone1_weights, dtype=torch.float32)\n",
    "\n",
    "# --- 3. Syllabe 2 ---\n",
    "syll2_classes = sorted(df['Syllabe 2'].dropna().unique())\n",
    "syll2_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=syll2_classes,\n",
    "                                     y=df['Syllabe 2'].dropna())\n",
    "syll2_weights_tensor = torch.tensor(syll2_weights, dtype=torch.float32)\n",
    "\n",
    "# --- 4. Tone 2 norm ---\n",
    "tone2_classes = sorted(df['Tone 2 norm'].dropna().unique())\n",
    "tone2_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=tone2_classes,\n",
    "                                     y=df['Tone 2 norm'].dropna())\n",
    "tone2_weights_tensor = torch.tensor(tone2_weights, dtype=torch.float32)\n",
    "\n",
    "syll1_loss_fn = torch.nn.CrossEntropyLoss(weight=syll1_weights_tensor)\n",
    "tone1_loss_fn = torch.nn.CrossEntropyLoss(weight=tone1_weights_tensor)\n",
    "syll2_loss_fn = torch.nn.CrossEntropyLoss(weight=syll2_weights_tensor)\n",
    "tone2_loss_fn = torch.nn.CrossEntropyLoss(weight=tone2_weights_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88be3e30",
   "metadata": {},
   "source": [
    "# 2. Data augmentation et Extraction des caractéristiques audio avec MelSpectrogram\n",
    "\n",
    "## 2.1. Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d70aa8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def augment_waveform(waveform, sample_rate=16000):\n",
    "    \"\"\"Applique des transformations audio de data augmentation.\"\"\"\n",
    "    \n",
    "    # 1. Ajouter bruit blanc (SNR ~20 dB)\n",
    "    if random.random() < 0.5:\n",
    "        noise = torch.randn_like(waveform) * 0.005\n",
    "        waveform = waveform + noise\n",
    "\n",
    "    # 2. Time shifting (décalage temporel aléatoire)\n",
    "    if random.random() < 0.5:\n",
    "        shift = int(random.uniform(-0.1, 0.1) * waveform.size(1))  # ±10%\n",
    "        waveform = torch.roll(waveform, shifts=shift, dims=1)\n",
    "\n",
    "    # 3. Pitch shift\n",
    "    if random.random() < 0.3:\n",
    "        semitone_shift = random.choice([-2, -1, 1, 2])\n",
    "        pitch_shift = T.PitchShift(sample_rate, n_steps=semitone_shift)\n",
    "        waveform = pitch_shift(waveform)\n",
    "\n",
    "    # 4. Time stretch (entre 0.8x et 1.2x)\n",
    "    if random.random() < 0.3:\n",
    "        stretch_rate = random.uniform(0.8, 1.2)\n",
    "        stretch = T.TimeStretch()\n",
    "        spec = T.Spectrogram()(waveform)\n",
    "        spec_stretched = stretch(spec, stretch_rate)\n",
    "        waveform = torchaudio.functional.istft(spec_stretched, n_fft=400)\n",
    "        waveform = waveform.unsqueeze(0)  # [1, T]\n",
    "\n",
    "    return waveform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b43854",
   "metadata": {},
   "source": [
    "## 2.2. Melspectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d963b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "def extract_melspectrogram(file_path, sample_rate=16000, n_mels=80):\n",
    "    try:\n",
    "        waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "        # Force mono (si 2 canaux, on moyenne)\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "        # Resample si nécessaire\n",
    "        if sr != sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        # Transformer Mel spectrogramme\n",
    "        mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sample_rate,\n",
    "            n_fft=1024,\n",
    "            hop_length=256,\n",
    "            n_mels=n_mels\n",
    "        )\n",
    "        mel_spec = mel_transform(waveform)\n",
    "\n",
    "        # Convertir en dB\n",
    "        mel_spec = torchaudio.transforms.AmplitudeToDB()(mel_spec)\n",
    "\n",
    "        # [1, F, T] → [T, F]\n",
    "        mel_spec = mel_spec.squeeze(0).transpose(0, 1)\n",
    "\n",
    "        # Vérifier la forme finale\n",
    "        if mel_spec.shape[1] != n_mels:\n",
    "            raise ValueError(f\"Mel spectrogram with invalid feature size: {mel_spec.shape}\")\n",
    "\n",
    "        return mel_spec\n",
    "\n",
    "    except Exception as e:\n",
    "        #print(f\"Erreur lors du traitement de {file_path}: {e}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aec42282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_melspectrogram_augmented(file_path, sample_rate=16000, n_mels=80):\n",
    "    try:\n",
    "        waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "        if sr != sample_rate:\n",
    "            resampler = T.Resample(sr, sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        # --- AJOUT DES AUGMENTATIONS ---\n",
    "        waveform = augment_waveform(waveform, sample_rate=sample_rate)\n",
    "\n",
    "        mel_transform = T.MelSpectrogram(\n",
    "            sample_rate=sample_rate,\n",
    "            n_fft=1024,\n",
    "            hop_length=256,\n",
    "            n_mels=n_mels\n",
    "        )\n",
    "        mel_spec = mel_transform(waveform)\n",
    "        mel_spec = T.AmplitudeToDB()(mel_spec)\n",
    "        mel_spec = mel_spec.squeeze(0).transpose(0, 1)\n",
    "\n",
    "        if mel_spec.shape[1] != n_mels:\n",
    "            raise ValueError(f\"Mel spectrogram with invalid feature size: {mel_spec.shape}\")\n",
    "\n",
    "        return mel_spec\n",
    "    except Exception as e:\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2661240",
   "metadata": {},
   "source": [
    "# 3. Tokenisation syllabique et construction du vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a07f6050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Créer un vocabulaire syllabique\n",
    "syllables = df[\"syllable_transcript\"].str.split().sum()\n",
    "syllable_counts = Counter(syllables)\n",
    "vocab = {s: i + 1 for i, s in enumerate(sorted(syllable_counts))}\n",
    "vocab[\"<BLANK>\"] = 0  # pour CTC\n",
    "\n",
    "# Encodage des transcriptions\n",
    "def encode_transcript(syllable_transcript):\n",
    "    return [vocab[s] for s in syllable_transcript.split()]\n",
    "\n",
    "df[\"encoded\"] = df[\"syllable_transcript\"].map(encode_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9e3145e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordId</th>\n",
       "      <th>Yemba</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>GroupeId</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Syllabe 1</th>\n",
       "      <th>Tone 1</th>\n",
       "      <th>Syllabe 2</th>\n",
       "      <th>Tone 2</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>syllable_transcript</th>\n",
       "      <th>Tone 1 norm</th>\n",
       "      <th>Tone 2 norm</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Apa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pa</td>\n",
       "      <td>bas</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_1.wav</td>\n",
       "      <td>a|bas pa|bas</td>\n",
       "      <td>bas</td>\n",
       "      <td>bas</td>\n",
       "      <td>[9, 198]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Apā</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pā</td>\n",
       "      <td>moyen</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_2.wav</td>\n",
       "      <td>a|bas pā|moyen</td>\n",
       "      <td>bas</td>\n",
       "      <td>moyen</td>\n",
       "      <td>[9, 201]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Apá</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pá</td>\n",
       "      <td>haut</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_3.wav</td>\n",
       "      <td>a|bas pá|haut</td>\n",
       "      <td>bas</td>\n",
       "      <td>haut</td>\n",
       "      <td>[9, 199]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Api</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pi</td>\n",
       "      <td>bas</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_1.wav</td>\n",
       "      <td>a|bas pi|bas</td>\n",
       "      <td>bas</td>\n",
       "      <td>bas</td>\n",
       "      <td>[9, 207]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Apī</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pī</td>\n",
       "      <td>moyen</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_2.wav</td>\n",
       "      <td>a|bas pī|moyen</td>\n",
       "      <td>bas</td>\n",
       "      <td>moyen</td>\n",
       "      <td>[9, 210]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WordId Yemba  Speaker  GroupeId  Statement Syllabe 1 Tone 1 Syllabe 2  \\\n",
       "0       1   Apa        1         1          1         a    bas        pa   \n",
       "1       2  Apā        1         1          2         a    bas       pā   \n",
       "2       3  Apá        1         1          3         a    bas       pá   \n",
       "3       4   Api        1         2          1         a    bas        pi   \n",
       "4       5  Apī        1         2          2         a    bas       pī   \n",
       "\n",
       "   Tone 2  \\\n",
       "0     bas   \n",
       "1   moyen   \n",
       "2    haut   \n",
       "3     bas   \n",
       "4  moyen    \n",
       "\n",
       "                                                                                                                                                                                          audio_path  \\\n",
       "0  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_1.wav   \n",
       "1  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_2.wav   \n",
       "2  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_3.wav   \n",
       "3  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_1.wav   \n",
       "4  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_2.wav   \n",
       "\n",
       "  syllable_transcript Tone 1 norm Tone 2 norm   encoded  \n",
       "0        a|bas pa|bas         bas         bas  [9, 198]  \n",
       "1     a|bas pā|moyen         bas       moyen  [9, 201]  \n",
       "2      a|bas pá|haut         bas        haut  [9, 199]  \n",
       "3        a|bas pi|bas         bas         bas  [9, 207]  \n",
       "4    a|bas pī|moyen          bas       moyen  [9, 210]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ac68f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3757    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_146/spkr_11_group_146_statement_2.wav\n",
       "3758    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_147/spkr_11_group_147_statement_1.wav\n",
       "3759    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_147/spkr_11_group_147_statement_2.wav\n",
       "3760    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_148/spkr_11_group_148_statement_1.wav\n",
       "3761    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_148/spkr_11_group_148_statement_2.wav\n",
       "Name: audio_path, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"audio_path\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c8ebd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers manquants : 0\n",
      "Empty DataFrame\n",
      "Columns: [audio_path, Speaker, GroupeId, Statement]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df[\"exists\"] = df[\"audio_path\"].apply(lambda p: os.path.exists(p))\n",
    "df = df[df[\"exists\"]]\n",
    "\n",
    "missing = df[~df[\"exists\"]]\n",
    "print(\"Fichiers manquants :\", len(missing))\n",
    "print(missing[[\"audio_path\", \"Speaker\", \"GroupeId\", \"Statement\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf70196b",
   "metadata": {},
   "source": [
    "# 4. Split en train/valid/test (80/10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b993bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668 train\n",
      "334 val\n",
      "334 test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val, test = train_test_split(test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(len(train), \"train\")\n",
    "print(len(val), \"val\")\n",
    "print(len(test), \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86635be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WordId', 'Yemba', 'Speaker', 'GroupeId', 'Statement', 'Syllabe 1',\n",
       "       'Tone 1', 'Syllabe 2', 'Tone 2', 'audio_path', 'syllable_transcript',\n",
       "       'Tone 1 norm', 'Tone 2 norm', 'encoded', 'exists'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2825cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={\"audio_path\": \"path\"})\n",
    "val = val.rename(columns={\"audio_path\": \"path\"})\n",
    "test = test.rename(columns={\"audio_path\": \"path\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5dda2a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifie que 'path' et 'encoded' sont bien dans chaque ligne\n",
    "train = train[train['path'].notnull() & train['encoded'].notnull()]\n",
    "val = val[val['path'].notnull() & val['encoded'].notnull()]\n",
    "test = test[test['path'].notnull() & test['encoded'].notnull()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f3e977",
   "metadata": {},
   "source": [
    "# 5. Dataset & DataLoader PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e35404ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class YembaDataset(Dataset):\n",
    "    def __init__(self, dataframe, processor, vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: DataFrame contenant les colonnes 'path' et 'encoded'\n",
    "            processor: fonction pour extraire un Mel spectrogramme à partir d'un fichier audio\n",
    "            vocab: dictionnaire {syllabe: index}\n",
    "        \"\"\"\n",
    "        self.data = dataframe\n",
    "        self.processor = processor\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            row = self.data.iloc[idx]\n",
    "            audio_path = row[\"path\"]\n",
    "            target_seq = row[\"encoded\"]\n",
    "\n",
    "            # 1. Extraire les features [T, F]\n",
    "            mel_spec = self.processor(audio_path)\n",
    "\n",
    "            if not isinstance(mel_spec, torch.Tensor) or mel_spec.dim() != 2 or mel_spec.shape[0] == 0:\n",
    "                raise ValueError(\"Mel spectrogramme vide ou invalide\")\n",
    "            \n",
    "            # 2. Convertir les cibles en Tensor\n",
    "            target_tensor = torch.tensor(target_seq, dtype=torch.long)\n",
    "\n",
    "            return mel_spec, target_tensor\n",
    "\n",
    "        except Exception as e:\n",
    "            #print(f\"[!] Erreur à l’index {idx} : {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f9abcc",
   "metadata": {},
   "source": [
    "# 6. Collate function pour padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a50feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "\"\"\"PAD_TOKEN = \"<pad>\"\n",
    "PAD_IDX = vocab.get(PAD_TOKEN, 0)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\n",
    "    Collate function pour DataLoader :\n",
    "    batch : list de tuples (mel_spec, target_tensor)\n",
    "            - mel_spec: Tensor de forme [T, F]\n",
    "            - target_tensor: Tensor de forme [L]\n",
    "    \"\n",
    "    # Supprimer les entrées invalides\n",
    "    \"batch = [sample for sample in batch if sample is not None]\n",
    "    \n",
    "    for i, item in enumerate(batch):\n",
    "        if not isinstance(item, tuple):\n",
    "            print(f\"[!] Élément invalide à l’index {i} : {item}\")\n",
    "        elif not isinstance(item[0], torch.Tensor):\n",
    "            print(f\"[!] Mel_spec invalide à l’index {i} : {item[0]}\")\n",
    "        elif not isinstance(item[1], torch.Tensor):\n",
    "            print(f\"[!] Target invalide à l’index {i} : {item[1]}\")\"\"\n",
    "    \n",
    "    if len(batch) == 0:\n",
    "        # Retourne des tensors vides pour éviter les plantages en cas de batch vide\n",
    "        return (\n",
    "            torch.empty(0, 0, 0),\n",
    "            torch.empty(0, 0, dtype=torch.long),\n",
    "            torch.empty(0, dtype=torch.long),\n",
    "            torch.empty(0, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    # Décompacter les mel_specs et cibles\n",
    "    mels, targets = zip(*batch)\n",
    "\n",
    "    # Pad des mel spectrogrammes (batch_first = True → [B, Tmax, F])\n",
    "    mels_padded = rnn_utils.pad_sequence(mels, batch_first=True)\n",
    "    input_lengths = torch.tensor([mel.shape[0] for mel in mels], dtype=torch.long)\n",
    "\n",
    "    # Pad des séquences cibles\n",
    "    targets_padded = rnn_utils.pad_sequence(targets, batch_first=True, padding_value=PAD_IDX)\n",
    "    target_lengths = torch.tensor([t.shape[0] for t in targets], dtype=torch.long)\n",
    "\n",
    "    return mels_padded, targets_padded, input_lengths, target_lengths\"\"\"\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Supprimer les entrées None\n",
    "    batch = [sample for sample in batch if sample is not None]\n",
    "\n",
    "    # Si le batch est vide, retourner des tenseurs vides valides\n",
    "    if len(batch) == 0:\n",
    "        return (\n",
    "            torch.empty(0, 0, 80),  # supposons F=80 (n_mels)\n",
    "            torch.empty(0, 0, dtype=torch.long),\n",
    "            torch.empty(0, dtype=torch.long),\n",
    "            torch.empty(0, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        mels, targets = zip(*batch)\n",
    "\n",
    "        mels_padded = rnn_utils.pad_sequence(mels, batch_first=True)\n",
    "        input_lengths = torch.tensor([mel.shape[0] for mel in mels], dtype=torch.long)\n",
    "\n",
    "        targets_padded = rnn_utils.pad_sequence(targets, batch_first=True, padding_value=PAD_IDX)\n",
    "        target_lengths = torch.tensor([len(t) for t in targets], dtype=torch.long)\n",
    "\n",
    "        return mels_padded, targets_padded, input_lengths, target_lengths\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Erreur dans collate_fn : {e}\")\n",
    "        return (\n",
    "            torch.empty(0, 0, 80),\n",
    "            torch.empty(0, 0, dtype=torch.long),\n",
    "            torch.empty(0, dtype=torch.long),\n",
    "            torch.empty(0, dtype=torch.long)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "966cc032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = YembaDataset(train, processor=extract_melspectrogram_augmented, vocab=vocab)\n",
    "val_dataset = YembaDataset(val, processor=extract_melspectrogram, vocab=vocab)\n",
    "test_dataset = YembaDataset(test, processor=extract_melspectrogram, vocab=vocab)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26745023",
   "metadata": {},
   "source": [
    "# 7. Modèle GRU+ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "813437bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers=num_layers,\n",
    "                          batch_first=True, bidirectional=True, dropout=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs, hidden = self.gru(x)  # outputs: [B, T, 2*H], hidden: [2L, B, H]\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 3, 1)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        # decoder_hidden: [B, H]\n",
    "        # encoder_outputs: [B, T, 2*H]\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, seq_len, 1)  # [B, T, H]\n",
    "        concat = torch.cat((decoder_hidden, encoder_outputs), dim=2)        # [B, T, 3H]\n",
    "        energy = self.attn(concat).squeeze(2)                               # [B, T]\n",
    "        attn_weights = F.softmax(energy, dim=1)                             # [B, T]\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)     # [B, 1, 2H]\n",
    "        return context.squeeze(1), attn_weights\n",
    "\n",
    "\n",
    "class GRUDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, num_layers=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(hidden_dim * 2, hidden_dim, num_layers=num_layers,\n",
    "                          batch_first=True, dropout=dropout)\n",
    "        self.out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, context_vector, hidden):\n",
    "        # context_vector: [B, 2H] → expand to [B, 1, 2H]\n",
    "        input_step = context_vector.unsqueeze(1)\n",
    "        output, hidden = self.gru(input_step, hidden)  # output: [B, 1, H]\n",
    "        prediction = self.out(output.squeeze(1))       # [B, vocab_size]\n",
    "        return prediction, hidden\n",
    "\n",
    "\n",
    "class GRUSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, vocab_size, encoder_layers=2, decoder_layers=1):\n",
    "        super().__init__()\n",
    "        self.bridge = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.encoder = GRUEncoder(input_dim, hidden_dim, encoder_layers)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.decoder = GRUDecoder(hidden_dim, vocab_size, decoder_layers)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.encoder_layers = encoder_layers\n",
    "\n",
    "    def forward(self, x, max_len=100):\n",
    "        encoder_outputs, hidden = self.encoder(x)  # hidden: [2*num_layers, B, H]\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # [2*L, B, H] → [L, 2, B, H]\n",
    "        hidden = hidden.view(self.encoder_layers, 2, batch_size, self.hidden_dim)\n",
    "\n",
    "        # Concat direction=0 et direction=1 → [L, B, 2H]\n",
    "        hidden_cat = torch.cat((hidden[:, 0], hidden[:, 1]), dim=-1)\n",
    "\n",
    "        # Projeter en [L, B, H] via Linear (bridge)\n",
    "        if not hasattr(self, \"bridge\"):\n",
    "            self.bridge = nn.Linear(self.hidden_dim * 2, self.hidden_dim).to(hidden_cat.device)\n",
    "\n",
    "        hidden_proj = self.bridge(hidden_cat)  # [L, B, H]\n",
    "\n",
    "        # Si besoin, adapter au nombre de couches du décodeur\n",
    "        if self.encoder_layers < self.decoder.gru.num_layers:\n",
    "            # Répéter pour compléter\n",
    "            num_missing = self.decoder.gru.num_layers - self.encoder_layers\n",
    "            repeat_hidden = hidden_proj[-1:, :, :].repeat(num_missing, 1, 1)\n",
    "            hidden_proj = torch.cat([hidden_proj, repeat_hidden], dim=0)\n",
    "        elif self.encoder_layers > self.decoder.gru.num_layers:\n",
    "            hidden_proj = hidden_proj[:self.decoder.gru.num_layers]\n",
    "\n",
    "        hidden = hidden_proj  # [decoder_layers, B, H]\n",
    "\n",
    "        outputs = []\n",
    "        for _ in range(max_len):\n",
    "            context, attn_weights = self.attention(hidden[-1], encoder_outputs)  # [B, 2H]\n",
    "            prediction, hidden = self.decoder(context, hidden)  # hidden: [decoder_layers, B, H]\n",
    "            outputs.append(prediction)\n",
    "\n",
    "        outputs = torch.stack(outputs, dim=1)  # [B, max_len, vocab_size]\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ce34d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import GRUSeq2Seq  # si défini dans model.py\n",
    "# ou bien directement : from ton_module import GRUSeq2Seq\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instanciation du modèle avec ton vocabulaire\n",
    "model = GRUSeq2Seq(input_dim=80, hidden_dim=256, vocab_size=len(vocab)).to(device)\n",
    "\n",
    "# Critère de perte adapté à une sortie par pas de temps\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "PAD_IDX = vocab[PAD_TOKEN] if PAD_TOKEN in vocab else 0  # ou choisis un autre index\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)  # définir PAD_IDX selon ton vocab\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Inverse vocab pour décodage (inchangé)\n",
    "vocab_inv = {v: k for k, v in vocab.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3988928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"vocabulaire.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vocab, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a94445",
   "metadata": {},
   "source": [
    "# 8. Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "020eea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CTCLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = GRUSeq2Seq(input_dim=80, hidden_dim=256, vocab_size=len(vocab),\n",
    "                   encoder_layers=2, decoder_layers=2).to(device)\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "PAD_IDX = vocab.get(PAD_TOKEN, 0)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for mel, target, input_lens, target_lens in tqdm(train_loader):\n",
    "        mel = mel.to(device)                 # [B, T, F]\n",
    "        target = target.to(device)           # [B, L]  (déjà pad)\n",
    "        \n",
    "        output = model(mel, max_len=target.shape[1])  # [B, L, vocab_size]\n",
    "        \n",
    "        # Reshape for CrossEntropy: [B*L, vocab_size] vs [B*L]\n",
    "        output = output.view(-1, output.size(2))  # [B*L, V]\n",
    "        target = target.view(-1)                  # [B*L]\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(train_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f6e5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Époque 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/667 [00:00<?, ?it/s]C:\\Users\\Christian\\AppData\\Local\\Temp\\ipykernel_2920\\463935989.py:30: UserWarning: The input to TimeStretch must be complex type. Providing non-complex tensor produces invalid results.\n",
      "  spec_stretched = stretch(spec, stretch_rate)\n",
      " 10%|▉         | 64/667 [22:23<4:17:01, 25.58s/it]"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "import time\n",
    "\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "PAD_IDX = vocab.get(PAD_TOKEN, 0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "num_epochs = 30\n",
    "train_losses, val_losses, wer_train, wer_val = [], [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n--- Époque {epoch + 1} ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # === TRAIN ===\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for mel, target, input_lens, target_lens in tqdm(train_loader):\n",
    "        mel, target = mel.to(device), target.to(device)\n",
    "\n",
    "        output = model(mel, max_len=target.size(1))  # [B, L, vocab_size]\n",
    "        output = output.view(-1, output.size(-1))    # [B*L, vocab_size]\n",
    "        target = target.view(-1)                     # [B*L]\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Perte entraînement : {avg_train_loss:.4f}\")\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # === VALID ===\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for mel, target, input_lens, target_lens in val_loader:\n",
    "            mel, target = mel.to(device), target.to(device)\n",
    "            output = model(mel, max_len=target.size(1))  # [B, L, vocab_size]\n",
    "            output = output.view(-1, output.size(-1))\n",
    "            target = target.view(-1)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Perte validation : {avg_val_loss:.4f}\")\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # === Évaluer WER simplifié ===\n",
    "    def compute_wer(loader):\n",
    "        model.eval()\n",
    "        predictions, references = [], []\n",
    "        with torch.no_grad():\n",
    "            for mel, target, _, target_lens in loader:\n",
    "                mel = mel.to(device)\n",
    "                output = model(mel, max_len=target.size(1))  # [B, L, vocab_size]\n",
    "                pred_ids = output.argmax(dim=-1).cpu()       # [B, L]\n",
    "\n",
    "                for pred_seq, ref_seq in zip(pred_ids, target):\n",
    "                    pred_str = \" \".join([vocab_inv.get(idx.item(), \"\") for idx in pred_seq if idx != PAD_IDX])\n",
    "                    ref_str = \" \".join([vocab_inv.get(idx.item(), \"\") for idx in ref_seq if idx != PAD_IDX])\n",
    "                    predictions.append(pred_str.strip())\n",
    "                    references.append(ref_str.strip())\n",
    "\n",
    "        return jiwer.wer(references, predictions)\n",
    "\n",
    "    wer_t = compute_wer(train_loader)\n",
    "    wer_v = compute_wer(val_loader)\n",
    "    wer_train.append(wer_t)\n",
    "    wer_val.append(wer_v)\n",
    "    print(f\"WER entraînement : {wer_t:.4f}\")\n",
    "    print(f\"WER validation   : {wer_v:.4f}\")\n",
    "    print(f\"Temps écoulé : {time.time() - start_time:.2f}s\")\n",
    "\n",
    "    # === Early stopping ===\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"full_model_GRUSeq2Seq.pt\")\n",
    "        print(\"✅ Nouveau meilleur modèle sauvegardé\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"⛔ Arrêt anticipé (early stopping)\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5adc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = list(range(1, len(train_losses) + 1))\n",
    "\n",
    "# 📉 Courbe des pertes (Loss)\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_losses, label='Perte Entraînement')\n",
    "plt.plot(epochs, val_losses, label='Perte Validation')\n",
    "plt.title(\"Évolution de la Perte\")\n",
    "plt.xlabel(\"Époque\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 🧠 Courbe du Word Error Rate (WER)\n",
    "plt.figure()\n",
    "plt.plot(epochs, wer_train, label='WER Entraînement')\n",
    "plt.plot(epochs, wer_val, label='WER Validation')\n",
    "plt.title(\"Évolution du WER (Word Error Rate)\")\n",
    "plt.xlabel(\"Époque\")\n",
    "plt.ylabel(\"WER\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94200257",
   "metadata": {},
   "source": [
    "# 9.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d459f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification du contenu du test_loader\n",
    "for batch in test_loader:\n",
    "    if batch is None or len(batch) == 0:\n",
    "        print(\"❌ Batch vide ou invalide.\")\n",
    "        continue\n",
    "\n",
    "    if len(batch) != 4:\n",
    "        print(f\"❌ Format inattendu du batch : attendu 4 éléments (mel, target, input_lens, target_lens), obtenu {len(batch)}\")\n",
    "        continue\n",
    "\n",
    "    mel, target, input_lens, target_lens = batch\n",
    "\n",
    "    print(\"✅ Batch trouvé avec données valides :\")\n",
    "    print(f\"- mel: {mel.shape}\")            # [B, T, F]\n",
    "    print(f\"- target: {target.shape}\")      # [B, L]\n",
    "    print(f\"- input_lens: {input_lens}\")    # liste des longueurs réelles d’entrée\n",
    "    print(f\"- target_lens: {target_lens}\")  # liste des longueurs cibles\n",
    "\n",
    "    # Afficher un exemple brut\n",
    "    print(\"\\nExemple brut :\")\n",
    "    print(\"→ mel[0].shape :\", mel[0].shape)\n",
    "    print(\"→ target[0] :\", target[0])\n",
    "    print(\"→ input_lens[0] :\", input_lens[0])\n",
    "    print(\"→ target_lens[0] :\", target_lens[0])\n",
    "    break  # On ne regarde que le premier batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b27275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_seq2seq(model, loader, vocab_inv, pad_idx=0):\n",
    "    model.eval()\n",
    "    predictions, references = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, target, input_lens, target_lens in loader:\n",
    "            if mel is None or target is None:\n",
    "                continue  # Sécurité\n",
    "\n",
    "            mel = mel.to(model.device if hasattr(model, \"device\") else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            target = target.to(mel.device)\n",
    "\n",
    "            output = model(mel, max_len=target.shape[1])  # [B, L, Vocab]\n",
    "            pred_tokens = output.argmax(dim=-1).cpu()     # [B, L]\n",
    "\n",
    "            for i in range(len(mel)):\n",
    "                # Prédiction\n",
    "                pred_seq = pred_tokens[i].tolist()\n",
    "                pred_seq = [p for p in pred_seq if p != pad_idx]\n",
    "                decoded_pred = [vocab_inv.get(p, \"\") for p in pred_seq]\n",
    "\n",
    "                # Référence\n",
    "                ref_seq = target[i][:target_lens[i]].tolist()\n",
    "                decoded_ref = [vocab_inv.get(t, \"\") for t in ref_seq]\n",
    "\n",
    "                predictions.append(\" \".join(decoded_pred))\n",
    "                references.append(\" \".join(decoded_ref))\n",
    "\n",
    "    # Sécurité : éviter la division par zéro\n",
    "    if len(references) == 0:\n",
    "        print(\"[⚠️] Aucune référence trouvée. Vérifie le contenu du test_loader.\")\n",
    "        return {\"WER\": None, \"CER\": None, \"SER\": None}\n",
    "\n",
    "    # Afficher un exemple pour vérification\n",
    "    print(\"\\n✅ Exemple de prédiction :\")\n",
    "    print(\"PRED :\", predictions[0])\n",
    "    print(\"REF  :\", references[0])\n",
    "\n",
    "    return {\n",
    "        \"WER\": wer(references, predictions),\n",
    "        \"CER\": cer(references, predictions),\n",
    "        \"SER\": sum([p != r for p, r in zip(predictions, references)]) / len(references)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e92c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_seq2seq(model, test_loader, vocab_inv, pad_idx=PAD_IDX)\n",
    "print(f\"WER : {results['WER']:.4f}\")\n",
    "print(f\"CER : {results['CER']:.4f}\")\n",
    "print(f\"SER : {results['SER']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e360a",
   "metadata": {},
   "source": [
    "# 10. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b14dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptation du YembaSataset et collate_fn pour qu'il retourne aussi les chemins des fichiers\n",
    "\n",
    "class YembaDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        mel = extract_melspectrogram(row[\"path\"])\n",
    "        label = torch.tensor(row[\"encoded\"], dtype=torch.long)\n",
    "        return mel, label, row[\"path\"]\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    mels, labels, paths = zip(*batch)\n",
    "    input_lengths = [mel.shape[0] for mel in mels]\n",
    "    label_lengths = [len(label) for label in labels]\n",
    "\n",
    "    mels_padded = nn.utils.rnn.pad_sequence(mels, batch_first=True)  # [B, T, F]\n",
    "    labels_cat = torch.cat(labels)\n",
    "\n",
    "    return mels_padded, labels_cat, torch.tensor(input_lengths), torch.tensor(label_lengths), list(paths)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    YembaDataset(test), \n",
    "    batch_size=8, \n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf655c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_prediction(pred_list):\n",
    "    cleaned = []\n",
    "    for token in pred_list:\n",
    "        if \"|\" in token:\n",
    "            base = token.split(\"|\")[0]\n",
    "        else:\n",
    "            base = token\n",
    "        if base.strip() == \"\" or base == \"∅\":\n",
    "            continue\n",
    "        cleaned.append(base)\n",
    "    return \"\".join(cleaned)\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for mel, target, input_lens, target_lens, paths in test_loader:\n",
    "        mel = mel.to(device)\n",
    "        output = model(mel).log_softmax(2)\n",
    "        pred = output.argmax(2).cpu()\n",
    "\n",
    "        start = 0\n",
    "        for i in range(len(mel)):\n",
    "            pred_seq = pred[i][:input_lens[i]].tolist()\n",
    "            decoded_pred = [vocab_inv.get(p, \"\") for p in pred_seq if p != 0]\n",
    "\n",
    "            t_len = target_lens[i]\n",
    "            ref_seq = target[start:start + t_len]\n",
    "            decoded_ref = [vocab_inv.get(t.item(), \"\") for t in ref_seq]\n",
    "\n",
    "            results.append({\n",
    "                \"fichier_audio\": os.path.basename(paths[i]),\n",
    "                \"prediction\": clean_prediction(decoded_pred),\n",
    "                \"reference\": clean_prediction(decoded_ref)\n",
    "            })\n",
    "\n",
    "            start += t_len\n",
    "\n",
    "df_resultats = pd.DataFrame(results)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef8f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_resultats))\n",
    "df_resultats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106fd1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct = df_resultats[df_resultats[\"prediction\"] == df_resultats[\"reference\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12acdcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_correct))\n",
    "df_correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d0a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = len(df_correct) / len(df_resultats)\n",
    "print(f\"Exact Match Accuracy : {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde5c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
