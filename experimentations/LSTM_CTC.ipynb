{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "779ebf55",
   "metadata": {},
   "source": [
    "# 1. Préparation des données et extraction des transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d810b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de255ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les transcriptions\n",
    "df = pd.read_excel(\"C:/Users/Christian/Desktop/YembaTones/dataset2.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "582878a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordId</th>\n",
       "      <th>Yemba</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>GroupeId</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Syllabe 1</th>\n",
       "      <th>Tone 1</th>\n",
       "      <th>Syllabe 2</th>\n",
       "      <th>Tone 2</th>\n",
       "      <th>Syllabe 3</th>\n",
       "      <th>Tone 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>3780</td>\n",
       "      <td>lezēn</td>\n",
       "      <td>11</td>\n",
       "      <td>146</td>\n",
       "      <td>2</td>\n",
       "      <td>le</td>\n",
       "      <td>bas</td>\n",
       "      <td>zēn</td>\n",
       "      <td>moyen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>3781</td>\n",
       "      <td>nzeŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zeŋ</td>\n",
       "      <td>bas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>3782</td>\n",
       "      <td>nzéŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zéŋ</td>\n",
       "      <td>haut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>3783</td>\n",
       "      <td>nzɔ̄ŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zɔ̄ŋ</td>\n",
       "      <td>moyen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>3784</td>\n",
       "      <td>nzɔŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zɔŋ</td>\n",
       "      <td>bas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WordId   Yemba  Speaker  GroupeId  Statement Syllabe 1 Tone 1 Syllabe 2  \\\n",
       "3779    3780  lezēn       11       146          2        le    bas      zēn   \n",
       "3780    3781    nzeŋ       11       147          1         n    bas       zeŋ   \n",
       "3781    3782   nzéŋ       11       147          2         n    bas      zéŋ   \n",
       "3782    3783   nzɔ̄ŋ       11       148          1         n    bas      zɔ̄ŋ   \n",
       "3783    3784    nzɔŋ       11       148          2         n    bas       zɔŋ   \n",
       "\n",
       "     Tone 2 Syllabe 3 Tone 3  \n",
       "3779  moyen       NaN    NaN  \n",
       "3780    bas       NaN    NaN  \n",
       "3781   haut       NaN    NaN  \n",
       "3782  moyen       NaN    NaN  \n",
       "3783    bas       NaN    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f8a6159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordId          0\n",
      "Yemba           0\n",
      "Speaker         0\n",
      "GroupeId        0\n",
      "Statement       0\n",
      "Syllabe 1       0\n",
      "Tone 1          0\n",
      "Syllabe 2      22\n",
      "Tone 2         22\n",
      "Syllabe 3    3762\n",
      "Tone 3       3762\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8713fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacement des valeurs manquates\n",
    "df[\"Syllabe 2\"] = df[\"Syllabe 2\"].fillna(\"∅\")\n",
    "df[\"Tone 2\"]    = df[\"Tone 2\"].fillna(\"∅\")\n",
    "df[\"Syllabe 3\"] = df[\"Syllabe 3\"].fillna(\"∅\")\n",
    "df[\"Tone 3\"]    = df[\"Tone 3\"].fillna(\"∅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69570c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génère les chemins des fichiers audio associés\n",
    "def get_audio_path(row):\n",
    "    return f\"C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_{row['Speaker']}/group_{row['GroupeId']}/spkr_{row['Speaker']}_group_{row['GroupeId']}_statement_{int(row['Statement'])}.wav\"\n",
    "\n",
    "df[\"audio_path\"] = df.apply(get_audio_path, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ec054be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordId</th>\n",
       "      <th>Yemba</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>GroupeId</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Syllabe 1</th>\n",
       "      <th>Tone 1</th>\n",
       "      <th>Syllabe 2</th>\n",
       "      <th>Tone 2</th>\n",
       "      <th>Syllabe 3</th>\n",
       "      <th>Tone 3</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>3780</td>\n",
       "      <td>lezēn</td>\n",
       "      <td>11</td>\n",
       "      <td>146</td>\n",
       "      <td>2</td>\n",
       "      <td>le</td>\n",
       "      <td>bas</td>\n",
       "      <td>zēn</td>\n",
       "      <td>moyen</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_146/spkr_11_group_146_statement_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>3781</td>\n",
       "      <td>nzeŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zeŋ</td>\n",
       "      <td>bas</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_147/spkr_11_group_147_statement_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>3782</td>\n",
       "      <td>nzéŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zéŋ</td>\n",
       "      <td>haut</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_147/spkr_11_group_147_statement_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>3783</td>\n",
       "      <td>nzɔ̄ŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zɔ̄ŋ</td>\n",
       "      <td>moyen</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_148/spkr_11_group_148_statement_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>3784</td>\n",
       "      <td>nzɔŋ</td>\n",
       "      <td>11</td>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>bas</td>\n",
       "      <td>zɔŋ</td>\n",
       "      <td>bas</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_148/spkr_11_group_148_statement_2.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WordId   Yemba  Speaker  GroupeId  Statement Syllabe 1 Tone 1 Syllabe 2  \\\n",
       "3779    3780  lezēn       11       146          2        le    bas      zēn   \n",
       "3780    3781    nzeŋ       11       147          1         n    bas       zeŋ   \n",
       "3781    3782   nzéŋ       11       147          2         n    bas      zéŋ   \n",
       "3782    3783   nzɔ̄ŋ       11       148          1         n    bas      zɔ̄ŋ   \n",
       "3783    3784    nzɔŋ       11       148          2         n    bas       zɔŋ   \n",
       "\n",
       "     Tone 2 Syllabe 3 Tone 3  \\\n",
       "3779  moyen         ∅      ∅   \n",
       "3780    bas         ∅      ∅   \n",
       "3781   haut         ∅      ∅   \n",
       "3782  moyen         ∅      ∅   \n",
       "3783    bas         ∅      ∅   \n",
       "\n",
       "                                                                                                                                                                                                   audio_path  \n",
       "3779  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_146/spkr_11_group_146_statement_2.wav  \n",
       "3780  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_147/spkr_11_group_147_statement_1.wav  \n",
       "3781  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_147/spkr_11_group_147_statement_2.wav  \n",
       "3782  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_148/spkr_11_group_148_statement_1.wav  \n",
       "3783  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_148/spkr_11_group_148_statement_2.wav  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a87a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les syllabes avec tons pour créer une transcription syllabique\n",
    "def combine_syllables(row):\n",
    "    syllables = []\n",
    "    for i in range(1, 4):\n",
    "        syll = row.get(f\"Syllabe {i}\")\n",
    "        tone = row.get(f\"Tone {i}\")\n",
    "        if pd.notnull(syll) and pd.notnull(tone):\n",
    "            syllables.append(f\"{syll}|{tone}\")\n",
    "    return \" \".join(syllables)\n",
    "\n",
    "df[\"syllable_transcript\"] = df.apply(combine_syllables, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df2aaabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordId</th>\n",
       "      <th>Yemba</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>GroupeId</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Syllabe 1</th>\n",
       "      <th>Tone 1</th>\n",
       "      <th>Syllabe 2</th>\n",
       "      <th>Tone 2</th>\n",
       "      <th>Syllabe 3</th>\n",
       "      <th>Tone 3</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>syllable_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Apa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pa</td>\n",
       "      <td>bas</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_1.wav</td>\n",
       "      <td>a|bas pa|bas ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Apā</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pā</td>\n",
       "      <td>moyen</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_2.wav</td>\n",
       "      <td>a|bas pā|moyen ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Apá</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pá</td>\n",
       "      <td>haut</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_3.wav</td>\n",
       "      <td>a|bas pá|haut ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Api</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pi</td>\n",
       "      <td>bas</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_1.wav</td>\n",
       "      <td>a|bas pi|bas ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Apī</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pī</td>\n",
       "      <td>moyen</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_2.wav</td>\n",
       "      <td>a|bas pī|moyen  ∅|∅</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WordId Yemba  Speaker  GroupeId  Statement Syllabe 1 Tone 1 Syllabe 2  \\\n",
       "0       1   Apa        1         1          1         a    bas        pa   \n",
       "1       2  Apā        1         1          2         a    bas       pā   \n",
       "2       3  Apá        1         1          3         a    bas       pá   \n",
       "3       4   Api        1         2          1         a    bas        pi   \n",
       "4       5  Apī        1         2          2         a    bas       pī   \n",
       "\n",
       "   Tone 2 Syllabe 3 Tone 3  \\\n",
       "0     bas         ∅      ∅   \n",
       "1   moyen         ∅      ∅   \n",
       "2    haut         ∅      ∅   \n",
       "3     bas         ∅      ∅   \n",
       "4  moyen          ∅      ∅   \n",
       "\n",
       "                                                                                                                                                                                          audio_path  \\\n",
       "0  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_1.wav   \n",
       "1  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_2.wav   \n",
       "2  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_3.wav   \n",
       "3  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_1.wav   \n",
       "4  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_2.wav   \n",
       "\n",
       "    syllable_transcript  \n",
       "0      a|bas pa|bas ∅|∅  \n",
       "1   a|bas pā|moyen ∅|∅  \n",
       "2    a|bas pá|haut ∅|∅  \n",
       "3      a|bas pi|bas ∅|∅  \n",
       "4  a|bas pī|moyen  ∅|∅  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c010adaf",
   "metadata": {},
   "source": [
    "# 2. Extraction des caractéristiques audio avec MelSpectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d93d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "def extract_melspectrogram(file_path, sample_rate=16000, n_mels=80):\n",
    "    try:\n",
    "        waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "        # Force mono (si 2 canaux, on moyenne)\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "        # Resample si nécessaire\n",
    "        if sr != sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        # Transformer Mel spectrogramme\n",
    "        mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sample_rate,\n",
    "            n_fft=1024,\n",
    "            hop_length=256,\n",
    "            n_mels=n_mels\n",
    "        )\n",
    "        mel_spec = mel_transform(waveform)\n",
    "\n",
    "        # Convertir en dB\n",
    "        mel_spec = torchaudio.transforms.AmplitudeToDB()(mel_spec)\n",
    "\n",
    "        # [1, F, T] → [T, F]\n",
    "        mel_spec = mel_spec.squeeze(0).transpose(0, 1)\n",
    "\n",
    "        # Vérifier la forme finale\n",
    "        if mel_spec.shape[1] != n_mels:\n",
    "            raise ValueError(f\"Mel spectrogram with invalid feature size: {mel_spec.shape}\")\n",
    "\n",
    "        return mel_spec\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6644c68a",
   "metadata": {},
   "source": [
    "# 3. Tokenisation syllabique et construction du vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d368113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Créer un vocabulaire syllabique\n",
    "syllables = df[\"syllable_transcript\"].str.split().sum()\n",
    "syllable_counts = Counter(syllables)\n",
    "vocab = {s: i + 1 for i, s in enumerate(sorted(syllable_counts))}\n",
    "vocab[\"<BLANK>\"] = 0  # pour CTC\n",
    "\n",
    "# Encodage des transcriptions\n",
    "def encode_transcript(syllable_transcript):\n",
    "    return [vocab[s] for s in syllable_transcript.split()]\n",
    "\n",
    "df[\"encoded\"] = df[\"syllable_transcript\"].map(encode_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e4da4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordId</th>\n",
       "      <th>Yemba</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>GroupeId</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Syllabe 1</th>\n",
       "      <th>Tone 1</th>\n",
       "      <th>Syllabe 2</th>\n",
       "      <th>Tone 2</th>\n",
       "      <th>Syllabe 3</th>\n",
       "      <th>Tone 3</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>syllable_transcript</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Apa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pa</td>\n",
       "      <td>bas</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_1.wav</td>\n",
       "      <td>a|bas pa|bas ∅|∅</td>\n",
       "      <td>[11, 200, 314]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Apā</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pā</td>\n",
       "      <td>moyen</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_2.wav</td>\n",
       "      <td>a|bas pā|moyen ∅|∅</td>\n",
       "      <td>[11, 203, 314]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Apá</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pá</td>\n",
       "      <td>haut</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_3.wav</td>\n",
       "      <td>a|bas pá|haut ∅|∅</td>\n",
       "      <td>[11, 201, 314]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Api</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pi</td>\n",
       "      <td>bas</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_1.wav</td>\n",
       "      <td>a|bas pi|bas ∅|∅</td>\n",
       "      <td>[11, 209, 314]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Apī</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>bas</td>\n",
       "      <td>pī</td>\n",
       "      <td>moyen</td>\n",
       "      <td>∅</td>\n",
       "      <td>∅</td>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_2.wav</td>\n",
       "      <td>a|bas pī|moyen  ∅|∅</td>\n",
       "      <td>[11, 212, 314]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WordId Yemba  Speaker  GroupeId  Statement Syllabe 1 Tone 1 Syllabe 2  \\\n",
       "0       1   Apa        1         1          1         a    bas        pa   \n",
       "1       2  Apā        1         1          2         a    bas       pā   \n",
       "2       3  Apá        1         1          3         a    bas       pá   \n",
       "3       4   Api        1         2          1         a    bas        pi   \n",
       "4       5  Apī        1         2          2         a    bas       pī   \n",
       "\n",
       "   Tone 2 Syllabe 3 Tone 3  \\\n",
       "0     bas         ∅      ∅   \n",
       "1   moyen         ∅      ∅   \n",
       "2    haut         ∅      ∅   \n",
       "3     bas         ∅      ∅   \n",
       "4  moyen          ∅      ∅   \n",
       "\n",
       "                                                                                                                                                                                          audio_path  \\\n",
       "0  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_1.wav   \n",
       "1  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_2.wav   \n",
       "2  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_1/spkr_1_group_1_statement_3.wav   \n",
       "3  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_1.wav   \n",
       "4  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_2/spkr_1_group_2_statement_2.wav   \n",
       "\n",
       "    syllable_transcript         encoded  \n",
       "0      a|bas pa|bas ∅|∅  [11, 200, 314]  \n",
       "1   a|bas pā|moyen ∅|∅  [11, 203, 314]  \n",
       "2    a|bas pá|haut ∅|∅  [11, 201, 314]  \n",
       "3      a|bas pi|bas ∅|∅  [11, 209, 314]  \n",
       "4  a|bas pī|moyen  ∅|∅  [11, 212, 314]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2d91d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3779    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_146/spkr_11_group_146_statement_2.wav\n",
       "3780    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_147/spkr_11_group_147_statement_1.wav\n",
       "3781    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_147/spkr_11_group_147_statement_2.wav\n",
       "3782    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_148/spkr_11_group_148_statement_1.wav\n",
       "3783    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_148/spkr_11_group_148_statement_2.wav\n",
       "Name: audio_path, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"audio_path\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27896f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers manquants : 0\n",
      "Empty DataFrame\n",
      "Columns: [audio_path, Speaker, GroupeId, Statement]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df[\"exists\"] = df[\"audio_path\"].apply(lambda p: os.path.exists(p))\n",
    "df = df[df[\"exists\"]]\n",
    "\n",
    "missing = df[~df[\"exists\"]]\n",
    "print(\"Fichiers manquants :\", len(missing))\n",
    "print(missing[[\"audio_path\", \"Speaker\", \"GroupeId\", \"Statement\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2660925",
   "metadata": {},
   "source": [
    "# 4. Split en train/valid/test (80/10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaf98c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2684 train\n",
      "335 val\n",
      "336 test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val, test = train_test_split(test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(len(train), \"train\")\n",
    "print(len(val), \"val\")\n",
    "print(len(test), \"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3790bd",
   "metadata": {},
   "source": [
    "# 5. Dataset & DataLoader PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e8b5e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class YembaDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        try:\n",
    "            mel = extract_melspectrogram(row[\"audio_path\"])\n",
    "            target = torch.tensor(row[\"encoded\"], dtype=torch.long)\n",
    "            return mel, target\n",
    "        except Exception as e:\n",
    "            return None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8fa545",
   "metadata": {},
   "source": [
    "# 6. Collate function pour padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c9ce050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Supprimer les entrées incorrectes\n",
    "    batch = [b for b in batch if b is not None and b[0] is not None and b[1] is not None]\n",
    "\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "\n",
    "    inputs, targets = zip(*batch)\n",
    "    input_lengths = [i.shape[0] for i in inputs]\n",
    "    target_lengths = [t.shape[0] for t in targets]\n",
    "\n",
    "    inputs_padded = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
    "    targets_cat = torch.cat(targets)\n",
    "\n",
    "    return inputs_padded, targets_cat, input_lengths, target_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f3bc329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Création des datasets\n",
    "train_dataset = YembaDataset(train)\n",
    "val_dataset = YembaDataset(val)\n",
    "test_dataset = YembaDataset(test)\n",
    "\n",
    "# Création des DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af611e",
   "metadata": {},
   "source": [
    "# 7. Modèle LSTM + CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "178cb07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTM_CTC(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, vocab_size, num_layers=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=False, \n",
    "            dropout=dropout if num_layers > 1 else 0.0  # dropout uniquement si >1 couche\n",
    "        )\n",
    "        self.classifier = nn.Linear(hidden_dim, vocab_size)  # pas de *2 ici\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)  \n",
    "        x = self.classifier(x)  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "008d3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTM_CTC(input_dim=80, hidden_dim=256, vocab_size=len(vocab)).to(device)\n",
    "criterion = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Vocab inverse pour décodage\n",
    "vocab_inv = {v: k for k, v in vocab.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbba170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"vocab3.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vocab, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1507ef",
   "metadata": {},
   "source": [
    "# 8. Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07ec9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CTCLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = LSTM_CTC(input_dim=80, hidden_dim=256, vocab_size=len(vocab))\n",
    "criterion = CTCLoss(blank=0, zero_infinity=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "train_loader = DataLoader(YembaDataset(train), batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(YembaDataset(val), batch_size=8, collate_fn=collate_fn)\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for mel, target, input_lens, target_lens in tqdm(train_loader):\n",
    "        logit = model(mel)\n",
    "        logit = logit.log_softmax(2).transpose(0, 1)\n",
    "        \n",
    "        output_lengths = model.compute_output_lengths(torch.tensor(input_lens)).to(device)\n",
    "        target_lens = torch.tensor(target_lens, dtype=torch.long).to(device)\n",
    "        \n",
    "        loss = criterion(logit, target, input_lens, target_lens)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cb6616d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Époque 1 ---\n",
      "Perte entraînement : 5.4871\n",
      "Perte validation : 3.4501\n",
      "WER entraînement : 0.9011\n",
      "WER validation   : 0.9133\n",
      "Temps d'entraînement : 459.74 secondes\n",
      "Nouveau meilleur modèle sauvegardé\n",
      "\n",
      "--- Époque 2 ---\n",
      "Perte entraînement : 3.1469\n",
      "Perte validation : 2.8777\n",
      "WER entraînement : 0.8979\n",
      "WER validation   : 0.8907\n",
      "Temps d'entraînement : 460.47 secondes\n",
      "Nouveau meilleur modèle sauvegardé\n",
      "\n",
      "--- Époque 3 ---\n",
      "Perte entraînement : 2.7744\n",
      "Perte validation : 2.8102\n",
      "WER entraînement : 0.8959\n",
      "WER validation   : 0.8926\n",
      "Temps d'entraînement : 393.77 secondes\n",
      "Nouveau meilleur modèle sauvegardé\n",
      "\n",
      "--- Époque 4 ---\n",
      "Perte entraînement : 2.7402\n",
      "Perte validation : 2.7852\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jiwer\u001b[38;5;241m.\u001b[39mwer(references, predictions)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Évaluer WER et afficher les résultats\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m wer_t \u001b[38;5;241m=\u001b[39m quick_wer(train_loader)\n\u001b[0;32m     84\u001b[0m wer_v \u001b[38;5;241m=\u001b[39m quick_wer(val_loader)\n\u001b[0;32m     85\u001b[0m wer_train\u001b[38;5;241m.\u001b[39mappend(wer_t)\n",
      "Cell \u001b[1;32mIn[23], line 71\u001b[0m, in \u001b[0;36mquick_wer\u001b[1;34m(loader)\u001b[0m\n\u001b[0;32m     69\u001b[0m predictions, references \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mel, target, input_lens, target_lens \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     72\u001b[0m         mel \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     73\u001b[0m         out \u001b[38;5;241m=\u001b[39m model(mel)\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    739\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m, in \u001b[0;36mYembaDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     11\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     mel \u001b[38;5;241m=\u001b[39m extract_melspectrogram(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_path\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     14\u001b[0m     target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoded\u001b[39m\u001b[38;5;124m\"\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mel, target\n",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m, in \u001b[0;36mextract_melspectrogram\u001b[1;34m(file_path, sample_rate, n_mels)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;241m!=\u001b[39m sample_rate:\n\u001b[0;32m     14\u001b[0m     resampler \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mResample(sr, sample_rate)\n\u001b[1;32m---> 15\u001b[0m     waveform \u001b[38;5;241m=\u001b[39m resampler(waveform)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Transformer Mel spectrogramme\u001b[39;00m\n\u001b[0;32m     18\u001b[0m mel_transform \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mMelSpectrogram(\n\u001b[0;32m     19\u001b[0m     sample_rate\u001b[38;5;241m=\u001b[39msample_rate,\n\u001b[0;32m     20\u001b[0m     n_fft\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[0;32m     21\u001b[0m     hop_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[0;32m     22\u001b[0m     n_mels\u001b[38;5;241m=\u001b[39mn_mels\n\u001b[0;32m     23\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchaudio\\transforms\\_transforms.py:979\u001b[0m, in \u001b[0;36mResample.forward\u001b[1;34m(self, waveform)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_freq:\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m waveform\n\u001b[1;32m--> 979\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _apply_sinc_resample_kernel(waveform, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_freq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_freq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcd, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchaudio\\functional\\functional.py:1466\u001b[0m, in \u001b[0;36m_apply_sinc_resample_kernel\u001b[1;34m(waveform, orig_freq, new_freq, gcd, kernel, width)\u001b[0m\n\u001b[0;32m   1464\u001b[0m num_wavs, length \u001b[38;5;241m=\u001b[39m waveform\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1465\u001b[0m waveform \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(waveform, (width, width \u001b[38;5;241m+\u001b[39m orig_freq))\n\u001b[1;32m-> 1466\u001b[0m resampled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mconv1d(waveform[:, \u001b[38;5;28;01mNone\u001b[39;00m], kernel, stride\u001b[38;5;241m=\u001b[39morig_freq)\n\u001b[0;32m   1467\u001b[0m resampled \u001b[38;5;241m=\u001b[39m resampled\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(num_wavs, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1468\u001b[0m target_length \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mceil(torch\u001b[38;5;241m.\u001b[39mas_tensor(new_freq \u001b[38;5;241m*\u001b[39m length \u001b[38;5;241m/\u001b[39m orig_freq))\u001b[38;5;241m.\u001b[39mlong()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "import time\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "num_epochs = 30\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "wer_train = []\n",
    "wer_val = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n--- Époque {epoch + 1} ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Mode entraînement\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for mel, target, input_lens, target_lens in train_loader:\n",
    "        mel, target = mel.to(device), target.to(device)\n",
    "\n",
    "        logits = model(mel)\n",
    "        logits = logits.log_softmax(2).transpose(0, 1)  # [T, B, C]\n",
    "\n",
    "        # recalcul des input_lengths après les CNN\n",
    "        output_lengths = torch.tensor(input_lens, dtype=torch.long)\n",
    "\n",
    "        loss = criterion(\n",
    "            logits,\n",
    "            target,\n",
    "            output_lengths.to(device),                 # Tenseur Long\n",
    "            torch.tensor(target_lens, dtype=torch.long).to(device)  # Conversion explicite\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Perte entraînement : {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Mode validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for mel, target, input_lens, target_lens in val_loader:\n",
    "            mel, target = mel.to(device), target.to(device)\n",
    "            logits = model(mel)\n",
    "            logits = logits.log_softmax(2).transpose(0, 1)\n",
    "\n",
    "            output_lengths = torch.tensor(input_lens, dtype=torch.long)\n",
    "            target_lens = torch.tensor(target_lens, dtype=torch.long).to(device)\n",
    "            loss = criterion(logits, target, output_lengths, target_lens)\n",
    "\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Perte validation : {val_loss:.4f}\")\n",
    "\n",
    "    # Stocker les pertes et WER à chaque époque\n",
    "    train_losses.append(total_loss / len(train_loader))\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # Évaluer WER train & val (simplifié)\n",
    "    def quick_wer(loader):\n",
    "        model.eval()\n",
    "        predictions, references = [], []\n",
    "        with torch.no_grad():\n",
    "            for mel, target, input_lens, target_lens in loader:\n",
    "                mel = mel.to(device)\n",
    "                out = model(mel).log_softmax(2)\n",
    "                pred = out.argmax(2)\n",
    "                for i in range(len(mel)):\n",
    "                    pred_seq = pred[i][:input_lens[i]].tolist()\n",
    "                    ref_seq = target[:target_lens[i]]\n",
    "                    predictions.append(\" \".join([vocab_inv.get(p, \"\") for p in pred_seq if p != 0]))\n",
    "                    references.append(\" \".join([vocab_inv.get(t.item(), \"\") for t in ref_seq]))\n",
    "        return jiwer.wer(references, predictions)\n",
    "\n",
    "    # Évaluer WER et afficher les résultats\n",
    "    wer_t = quick_wer(train_loader)\n",
    "    wer_v = quick_wer(val_loader)\n",
    "    wer_train.append(wer_t)\n",
    "    wer_val.append(wer_v)\n",
    "\n",
    "    print(f\"WER entraînement : {wer_t:.4f}\")\n",
    "    print(f\"WER validation   : {wer_v:.4f}\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Temps d'entraînement : {(end_time - start_time):.2f} secondes\")\n",
    "        \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model_LSTM_CTC.pt\")\n",
    "        print(\"Nouveau meilleur modèle sauvegardé\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Arrêt anticipé (early stopping)\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d61f9d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (4,) and (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 🧠 Courbe du Word Error Rate (WER)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m---> 18\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, wer_train, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWER Entraînement\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, wer_val, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWER Validation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÉvolution du WER (Word Error Rate)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   2813\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   2814\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[0;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (4,) and (3,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = list(range(1, len(train_losses) + 1))\n",
    "\n",
    "# 📉 Courbe des pertes (Loss)\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_losses, label='Perte Entraînement')\n",
    "plt.plot(epochs, val_losses, label='Perte Validation')\n",
    "plt.title(\"Évolution de la Perte\")\n",
    "plt.xlabel(\"Époque\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 🧠 Courbe du Word Error Rate (WER)\n",
    "plt.figure()\n",
    "plt.plot(epochs, wer_train, label='WER Entraînement')\n",
    "plt.plot(epochs, wer_val, label='WER Validation')\n",
    "plt.title(\"Évolution du WER (Word Error Rate)\")\n",
    "plt.xlabel(\"Époque\")\n",
    "plt.ylabel(\"WER\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff29d1d",
   "metadata": {},
   "source": [
    "# 9.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a01f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, vocab_inv):\n",
    "    model.eval()\n",
    "    predictions, references = [], []\n",
    "    with torch.no_grad():\n",
    "        for mel, target, input_lens, target_lens in loader:\n",
    "            out = model(mel).log_softmax(2)\n",
    "            pred = out.argmax(2)\n",
    "            for i in range(len(mel)):\n",
    "                pred_seq = pred[i][:input_lens[i]].tolist()\n",
    "                decoded = [vocab_inv[p] for p in pred_seq if p in vocab_inv and p != 0]\n",
    "                ref = [vocab_inv[t.item()] for t in target[:target_lens[i]]]\n",
    "                predictions.append(\" \".join(decoded))\n",
    "                references.append(\" \".join(ref))\n",
    "\n",
    "    wer = jiwer.wer(references, predictions)\n",
    "    cer = jiwer.cer(references, predictions)\n",
    "    ser = sum([r != p for r, p in zip(references, predictions)]) / len(references)\n",
    "    return wer, cer, ser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df0f961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER : 0.8536\n",
      "CER : 0.5911\n",
      "SER : 1.0000\n"
     ]
    }
   ],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "# Charger le meilleur modèle\n",
    "model.load_state_dict(torch.load(\"best_model_LSTM_CTC.pt\"))\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_refs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mel, target, input_lens, target_lens in test_loader:\n",
    "        mel = mel.to(device)\n",
    "        output = model(mel).log_softmax(2)\n",
    "        pred = output.argmax(2)  # [B, T]\n",
    "        pred = pred.cpu()\n",
    "\n",
    "        for i in range(len(mel)):\n",
    "            pred_seq = pred[i][:input_lens[i]].tolist()\n",
    "            decoded_pred = [vocab_inv.get(p, \"\") for p in pred_seq if p != 0]\n",
    "            ref_seq = target[:target_lens[i]]\n",
    "            decoded_ref = [vocab_inv.get(t.item(), \"\") for t in ref_seq]\n",
    "            all_preds.append(\" \".join(decoded_pred))\n",
    "            all_refs.append(\" \".join(decoded_ref))\n",
    "\n",
    "# Évaluation\n",
    "print(f\"WER : {wer(all_refs, all_preds):.4f}\")\n",
    "print(f\"CER : {cer(all_refs, all_preds):.4f}\")\n",
    "print(f\"SER : {sum(p != r for p, r in zip(all_preds, all_refs)) / len(all_preds):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16a689db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER : 0.8726\n",
      "CER : 0.5841\n",
      "SER : 1.0000\n"
     ]
    }
   ],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "# Charger le meilleur modèle\n",
    "model.load_state_dict(torch.load(\"best_model_LSTM_CTC.pt\"))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_refs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mel, target, input_lens, target_lens in test_loader:\n",
    "        mel = mel.to(device)\n",
    "        output = model(mel).log_softmax(2)\n",
    "        pred = output.argmax(2)  # [B, T]\n",
    "        pred = pred.cpu()\n",
    "\n",
    "        # target est concaténé, on utilise un pointeur\n",
    "        start = 0\n",
    "        for i in range(len(mel)):\n",
    "            pred_seq = pred[i][:input_lens[i]].tolist()\n",
    "            decoded_pred = [vocab_inv.get(p, \"\") for p in pred_seq if p != 0]\n",
    "\n",
    "            t_len = target_lens[i]\n",
    "            ref_seq = target[start:start + t_len]\n",
    "            decoded_ref = [vocab_inv.get(t.item(), \"\") for t in ref_seq]\n",
    "\n",
    "            all_preds.append(\" \".join(decoded_pred))\n",
    "            all_refs.append(\" \".join(decoded_ref))\n",
    "\n",
    "            start += t_len\n",
    "\n",
    "# Évaluation\n",
    "print(f\"WER : {wer(all_refs, all_preds):.4f}\")\n",
    "print(f\"CER : {cer(all_refs, all_preds):.4f}\")\n",
    "print(f\"SER : {sum(p != r for p, r in zip(all_preds, all_refs)) / len(all_preds):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783834be",
   "metadata": {},
   "source": [
    "# 10. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15f4eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptation du YembaSataset et collate_fn pour qu'iol retourne aussi les chemins des fichiers\n",
    "\n",
    "class YembaDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        mel = extract_melspectrogram(row[\"audio_path\"])\n",
    "        label = torch.tensor(row[\"encoded\"], dtype=torch.long)\n",
    "        return mel, label, row[\"audio_path\"]\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    mels, labels, paths = zip(*batch)\n",
    "    input_lengths = [mel.shape[0] for mel in mels]\n",
    "    label_lengths = [len(label) for label in labels]\n",
    "\n",
    "    mels_padded = nn.utils.rnn.pad_sequence(mels, batch_first=True)  # [B, T, F]\n",
    "    labels_cat = torch.cat(labels)\n",
    "\n",
    "    return mels_padded, labels_cat, torch.tensor(input_lengths), torch.tensor(label_lengths), list(paths)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    YembaDataset(test), \n",
    "    batch_size=8, \n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01aae9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Évaluation + collecte des résultats avec noms de fichiers\n",
    "results = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for mel, target, input_lens, target_lens, paths in test_loader:\n",
    "        mel = mel.to(device)\n",
    "        output = model(mel).log_softmax(2)\n",
    "        pred = output.argmax(2).cpu()\n",
    "\n",
    "        start = 0\n",
    "        for i in range(len(mel)):\n",
    "            pred_seq = pred[i][:input_lens[i]].tolist()\n",
    "            decoded_pred = [vocab_inv.get(p, \"\") for p in pred_seq if p != 0]\n",
    "\n",
    "            t_len = target_lens[i]\n",
    "            ref_seq = target[start:start + t_len]\n",
    "            decoded_ref = [vocab_inv.get(t.item(), \"\") for t in ref_seq]\n",
    "\n",
    "            results.append({\n",
    "                \"fichier_audio\": paths[i],\n",
    "                \"prediction\": \" \".join(decoded_pred),\n",
    "                \"reference\": \" \".join(decoded_ref)\n",
    "            })\n",
    "\n",
    "            start += t_len\n",
    "\n",
    "# Création du DataFrame\n",
    "df_resultats = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11d2eb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fichier_audio</th>\n",
       "      <th>prediction</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_5/group_79/spkr_5_group_79_statement_3.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>N|bas tí |haut ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_49/spkr_11_group_49_statement_1.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>n|bas tshɛ|bas ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_3/group_111/spkr_3_group_111_statement_1.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>a|bas kem|bas ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_8/group_36/spkr_8_group_36_statement_2.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>n|bas tɔ̄ŋ|moyen ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_76/spkr_1_group_76_statement_1.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>N|haut chʉ̄ |moyen ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_20/spkr_1_group_20_statement_2.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>m|bas bɛ̄|moyen ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_4/group_15/spkr_4_group_15_statement_2.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>m|haut bǝ̄|moyen ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_8/group_121/spkr_8_group_121_statement_2.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>Le|bas kwɛ̄|moyen ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_9/group_48/spkr_9_group_48_statement_2.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>n|haut tshí|haut ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_7/group_70/spkr_7_group_70_statement_2.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>Le|bas whʉ |bas ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_3/group_66/spkr_3_group_66_statement_1.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>Le|bas pfū' |moyen ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_7/group_14/spkr_7_group_14_statement_3.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>m|haut bēŋ|moyen ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_70/spkr_11_group_70_statement_1.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>le|bas whʉ̄ |moyen ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_9/group_20/spkr_9_group_20_statement_1.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>m|bas bɛ|bas ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_5/group_56/spkr_5_group_56_statement_1.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>n|bas zɔŋ|bas ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_22/spkr_11_group_22_statement_1.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>n|bas deŋ|bas ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_3/group_134/spkr_3_group_134_statement_2.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>Le|bas māk|moyen ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_7/group_108/spkr_7_group_108_statement_2.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>ŋ|bas kák|haut ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_120/spkr_1_group_120_statement_2.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>Le|bas kūp|moyen ∅|∅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_3/group_118/spkr_3_group_118_statement_2.wav</td>\n",
       "      <td>Le|bas gap|bas ∅|∅ ∅|∅</td>\n",
       "      <td>a|bas kɔ'|bas ∅|∅</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                            fichier_audio  \\\n",
       "0     C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_5/group_79/spkr_5_group_79_statement_3.wav   \n",
       "1   C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_49/spkr_11_group_49_statement_1.wav   \n",
       "2   C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_3/group_111/spkr_3_group_111_statement_1.wav   \n",
       "3     C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_8/group_36/spkr_8_group_36_statement_2.wav   \n",
       "4     C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_76/spkr_1_group_76_statement_1.wav   \n",
       "5     C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_20/spkr_1_group_20_statement_2.wav   \n",
       "6     C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_4/group_15/spkr_4_group_15_statement_2.wav   \n",
       "7   C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_8/group_121/spkr_8_group_121_statement_2.wav   \n",
       "8     C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_9/group_48/spkr_9_group_48_statement_2.wav   \n",
       "9     C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_7/group_70/spkr_7_group_70_statement_2.wav   \n",
       "10    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_3/group_66/spkr_3_group_66_statement_1.wav   \n",
       "11    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_7/group_14/spkr_7_group_14_statement_3.wav   \n",
       "12  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_70/spkr_11_group_70_statement_1.wav   \n",
       "13    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_9/group_20/spkr_9_group_20_statement_1.wav   \n",
       "14    C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_5/group_56/spkr_5_group_56_statement_1.wav   \n",
       "15  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_11/group_22/spkr_11_group_22_statement_1.wav   \n",
       "16  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_3/group_134/spkr_3_group_134_statement_2.wav   \n",
       "17  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_7/group_108/spkr_7_group_108_statement_2.wav   \n",
       "18  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_1/group_120/spkr_1_group_120_statement_2.wav   \n",
       "19  C:/Users/Christian/Desktop/YembaTones/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_3/group_118/spkr_3_group_118_statement_2.wav   \n",
       "\n",
       "                prediction                reference  \n",
       "0   Le|bas gap|bas ∅|∅ ∅|∅      N|bas tí |haut ∅|∅  \n",
       "1   Le|bas gap|bas ∅|∅ ∅|∅       n|bas tshɛ|bas ∅|∅  \n",
       "2   Le|bas gap|bas ∅|∅ ∅|∅        a|bas kem|bas ∅|∅  \n",
       "3   Le|bas gap|bas ∅|∅ ∅|∅     n|bas tɔ̄ŋ|moyen ∅|∅  \n",
       "4   Le|bas gap|bas ∅|∅ ∅|∅   N|haut chʉ̄ |moyen ∅|∅  \n",
       "5   Le|bas gap|bas ∅|∅ ∅|∅      m|bas bɛ̄|moyen ∅|∅  \n",
       "6   Le|bas gap|bas ∅|∅ ∅|∅     m|haut bǝ̄|moyen ∅|∅  \n",
       "7   Le|bas gap|bas ∅|∅ ∅|∅    Le|bas kwɛ̄|moyen ∅|∅  \n",
       "8   Le|bas gap|bas ∅|∅ ∅|∅    n|haut tshí|haut ∅|∅  \n",
       "9   Le|bas gap|bas ∅|∅ ∅|∅      Le|bas whʉ |bas ∅|∅  \n",
       "10  Le|bas gap|bas ∅|∅ ∅|∅  Le|bas pfū' |moyen ∅|∅  \n",
       "11  Le|bas gap|bas ∅|∅ ∅|∅    m|haut bēŋ|moyen ∅|∅  \n",
       "12  Le|bas gap|bas ∅|∅ ∅|∅   le|bas whʉ̄ |moyen ∅|∅  \n",
       "13  Le|bas gap|bas ∅|∅ ∅|∅         m|bas bɛ|bas ∅|∅  \n",
       "14  Le|bas gap|bas ∅|∅ ∅|∅        n|bas zɔŋ|bas ∅|∅  \n",
       "15  Le|bas gap|bas ∅|∅ ∅|∅        n|bas deŋ|bas ∅|∅  \n",
       "16  Le|bas gap|bas ∅|∅ ∅|∅    Le|bas māk|moyen ∅|∅  \n",
       "17  Le|bas gap|bas ∅|∅ ∅|∅      ŋ|bas kák|haut ∅|∅  \n",
       "18  Le|bas gap|bas ∅|∅ ∅|∅    Le|bas kūp|moyen ∅|∅  \n",
       "19  Le|bas gap|bas ∅|∅ ∅|∅        a|bas kɔ'|bas ∅|∅  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultats.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331cb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd4c96fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_erreurs(predictions, references):\n",
    "    for ref, pred in zip(references, predictions):\n",
    "        if ref != pred:\n",
    "            print(f\"\\nRef : {ref}\\nPred: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f261a101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔴 Sample 0\n",
      "Référence : N|bas tí |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 1\n",
      "Référence : n|bas tshɛ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 2\n",
      "Référence : a|bas kem|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 3\n",
      "Référence : n|bas tɔ̄ŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 4\n",
      "Référence : N|haut chʉ̄ |moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 5\n",
      "Référence : m|bas bɛ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 6\n",
      "Référence : m|haut bǝ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 7\n",
      "Référence : Le|bas kwɛ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 8\n",
      "Référence : n|haut tshí|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 9\n",
      "Référence : Le|bas whʉ |bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 10\n",
      "Référence : Le|bas pfū' |moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 11\n",
      "Référence : m|haut bēŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 12\n",
      "Référence : le|bas whʉ̄ |moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 13\n",
      "Référence : m|bas bɛ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 14\n",
      "Référence : n|bas zɔŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 15\n",
      "Référence : n|bas deŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 16\n",
      "Référence : Le|bas māk|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 17\n",
      "Référence : ŋ|bas kák|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 18\n",
      "Référence : Le|bas kūp|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 19\n",
      "Référence : a|bas kɔ'|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 20\n",
      "Référence : ŋ|bas kiŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 21\n",
      "Référence : n|bas zeŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 22\n",
      "Référence : a|bas kup|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 23\n",
      "Référence : Le|bas lo|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 24\n",
      "Référence : Le|bas kyɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 25\n",
      "Référence : N|haut záʼ |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 26\n",
      "Référence : a|bas kūp|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 27\n",
      "Référence : a|bas pá|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 28\n",
      "Référence : Le|bas whʉ |bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 29\n",
      "Référence : M|haut vɛ́t |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 30\n",
      "Référence : Sé|haut sā|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 31\n",
      "Référence : N|haut káp |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 32\n",
      "Référence : Le|bas cuŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 33\n",
      "Référence : Le|bas kā|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 34\n",
      "Référence : a|bas fé|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 35\n",
      "Référence : m|bas bi|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 36\n",
      "Référence : n|bas ta|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 37\n",
      "Référence : n|haut cɔ́k|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 38\n",
      "Référence : Le|bas lū'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 39\n",
      "Référence : a|bas kem|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 40\n",
      "Référence : n|haut tēm|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 41\n",
      "Référence : n|bas daŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 42\n",
      "Référence : n|bas dǝ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 43\n",
      "Référence : Le|bas lu|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 44\n",
      "Référence : n|haut tā'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 45\n",
      "Référence : Le|bas cuŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 46\n",
      "Référence : Le|bas fɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 47\n",
      "Référence : n|haut dū|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 48\n",
      "Référence : Le|bas pfu'|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 49\n",
      "Référence : n|bas zeŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 50\n",
      "Référence : ŋ|bas kák|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 51\n",
      "Référence : a|bas fe|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 52\n",
      "Référence : Me|bas laŋ |bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 53\n",
      "Référence : a|bas lúŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 54\n",
      "Référence : n|bas zeŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 55\n",
      "Référence : N|haut dáp |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 56\n",
      "Référence : Le|bas lúŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 57\n",
      "Référence : n|bas tshi|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 58\n",
      "Référence : a|bas kūp|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 59\n",
      "Référence : Le|bas lūŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 60\n",
      "Référence : m|bas bɔ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 61\n",
      "Référence : n|bas zém|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 62\n",
      "Référence : n|haut tǝ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 63\n",
      "Référence : Le|bas kiá|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 64\n",
      "Référence : Le|bas fēm|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 65\n",
      "Référence : n|bas dɔ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 66\n",
      "Référence : n|haut tsɔ́' |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 67\n",
      "Référence : n|bas dɔ̄ŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 68\n",
      "Référence : Seŋ |bas ∅|∅ ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 69\n",
      "Référence : n|haut tswhī|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 70\n",
      "Référence : n|bas dāŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 71\n",
      "Référence : n|haut tɛ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 72\n",
      "Référence : Le|bas kōk|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 73\n",
      "Référence : N|bas chʉ́ |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 74\n",
      "Référence : a|bas fū'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 75\n",
      "Référence : Sé|haut sā|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 76\n",
      "Référence : n|haut zá'|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 77\n",
      "Référence : m|bas bí|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 78\n",
      "Référence : m|haut búŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 79\n",
      "Référence : Le|bas kɔ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 80\n",
      "Référence : a|bas kup|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 81\n",
      "Référence : n|haut tsɔ́' |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 82\n",
      "Référence : a|bas fhō|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 83\n",
      "Référence : m|bas bīŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 84\n",
      "Référence : a|bas kem|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 85\n",
      "Référence : Le|bas kwɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 86\n",
      "Référence : le|bas cɔp|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 87\n",
      "Référence : Le|bas kwɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 88\n",
      "Référence : Le|bas kwɛt|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 89\n",
      "Référence : Le|bas pé|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 90\n",
      "Référence : Le|bas ko|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 91\n",
      "Référence : Le|bas lɔk |bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 92\n",
      "Référence : n|haut zāŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 93\n",
      "Référence : Le|bas mak|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 94\n",
      "Référence : a|bas pī|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 95\n",
      "Référence : ŋ|bas kā'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 96\n",
      "Référence : a|bas fū'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 97\n",
      "Référence : Le|bas kwɛt|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 98\n",
      "Référence : ŋ|bas kíŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 99\n",
      "Référence : m|haut bǝ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 100\n",
      "Référence : Le|bas fāk|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 101\n",
      "Référence : n|haut dó|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 102\n",
      "Référence : m|haut bǝ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 103\n",
      "Référence : n|haut dó|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 104\n",
      "Référence : Le|bas kwɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 105\n",
      "Référence : Le|bas kūp|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 106\n",
      "Référence : n|bas tɔɔ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 107\n",
      "Référence : a|bas tswɛt|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 108\n",
      "Référence : m|bas bɔ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 109\n",
      "Référence : n|haut tsāp|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 110\n",
      "Référence : n|haut tsáp|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 111\n",
      "Référence : n|bas tǝ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 112\n",
      "Référence : n|bas tsap|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 113\n",
      "Référence : le|bas zen|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 114\n",
      "Référence : a|bas tú'|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 115\n",
      "Référence : n|bas tshí|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 116\n",
      "Référence : n|haut dʉ̄'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 117\n",
      "Référence : N|haut cʉ́ʼ |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 118\n",
      "Référence : n|haut dǝ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 119\n",
      "Référence : le|bas zēn|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 120\n",
      "Référence : n|bas tswīŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 121\n",
      "Référence : n|bas ta|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 122\n",
      "Référence : m|bas bi|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 123\n",
      "Référence : n|haut dɛ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 124\n",
      "Référence : n|haut tswīŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 125\n",
      "Référence : ŋ|bas kyɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 126\n",
      "Référence : Le|bas lúŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 127\n",
      "Référence : Le|bas kō|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 128\n",
      "Référence : n|bas zéŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 129\n",
      "Référence : M|haut vɛ̄t |moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 130\n",
      "Référence : m|bas bǝ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 131\n",
      "Référence : n|bas dʉ'|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 132\n",
      "Référence : Le|bas pāp|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 133\n",
      "Référence : n|haut zēŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 134\n",
      "Référence : a|bas pi|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 135\n",
      "Référence : ŋ|bas kyɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 136\n",
      "Référence : n|bas tɔ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 137\n",
      "Référence : m|haut bɛ́|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 138\n",
      "Référence : N|haut dáp |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 139\n",
      "Référence : n|bas tshí|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 140\n",
      "Référence : Le|bas kwɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 141\n",
      "Référence : a|bas ka|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 142\n",
      "Référence : Me|bas nu |bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 143\n",
      "Référence : n|bas tshɛ́|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 144\n",
      "Référence : m|bas bǝ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 145\n",
      "Référence : Le|bas kwɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 146\n",
      "Référence : le|bas zēn|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 147\n",
      "Référence : n|haut tsi |bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 148\n",
      "Référence : n|haut tɔ́|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 149\n",
      "Référence : ŋ|bas kyɛt|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 150\n",
      "Référence : n|haut tshí|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 151\n",
      "Référence : n|bas zém|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 152\n",
      "Référence : m|haut bɔ́k|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 153\n",
      "Référence : ŋ|bas kák|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 154\n",
      "Référence : n|haut tsɔ́' |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 155\n",
      "Référence : N|haut cʉ́ʼ |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 156\n",
      "Référence : a|bas fu'|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 157\n",
      "Référence : le|bas cu'|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 158\n",
      "Référence : Le|bas fho|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 159\n",
      "Référence : a|bas twɛt|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 160\n",
      "Référence : Le|bas tɔ̄ŋ |moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 161\n",
      "Référence : Le|bas cuŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 162\n",
      "Référence : Le|bas lo|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 163\n",
      "Référence : n|bas zéŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 164\n",
      "Référence : n|haut cɔ́k|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 165\n",
      "Référence : Le|bas pé|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 166\n",
      "Référence : Le|bas pfu'|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 167\n",
      "Référence : n|haut tsáp|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 168\n",
      "Référence : Sé|haut sá|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 169\n",
      "Référence : N|bas dap|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 170\n",
      "Référence : ŋ|bas ghī|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 171\n",
      "Référence : m|bas bɔ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 172\n",
      "Référence : ń|haut zá|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 173\n",
      "Référence : m|bas bhi|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 174\n",
      "Référence : m|bas bīŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 175\n",
      "Référence : Le|bas tɔŋ |bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 176\n",
      "Référence : m|haut bīŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 177\n",
      "Référence : n|haut dū|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 178\n",
      "Référence : ŋ|bas kyɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 179\n",
      "Référence : Le|bas pē|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 180\n",
      "Référence : N|haut cʉ́ʼ |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 181\n",
      "Référence : Me|bas fɔ |bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 182\n",
      "Référence : a|bas féŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 183\n",
      "Référence : m|bas beŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 184\n",
      "Référence : n|bas zéŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 185\n",
      "Référence : a|bas tswɛt|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 186\n",
      "Référence : Le|bas lɔ̄k|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 187\n",
      "Référence : a|bas fe|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 188\n",
      "Référence : Le|bas kāŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 189\n",
      "Référence : n|haut tēm|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 190\n",
      "Référence : Le|bas kyɛt|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 191\n",
      "Référence : Le|bas pē|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 192\n",
      "Référence : n|haut tɔ́ŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 193\n",
      "Référence : n|bas tā'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 194\n",
      "Référence : N|haut zāʼ |moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 195\n",
      "Référence : n|haut cɔ́k|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 196\n",
      "Référence : É|haut sá'|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 197\n",
      "Référence : N|bas chʉ́ |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 198\n",
      "Référence : n|bas tsɔ́ŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 199\n",
      "Référence : n|bas ta|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 200\n",
      "Référence : n|bas tā'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 201\n",
      "Référence : n|bas zɔ̄ŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 202\n",
      "Référence : m|haut vhó|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 203\n",
      "Référence : Le|bas tá |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 204\n",
      "Référence : Le|bas whʉ |bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 205\n",
      "Référence : ŋ|bas gwen|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 206\n",
      "Référence : Le|bas tɔ̄ŋ |moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 207\n",
      "Référence : a|bas tū'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 208\n",
      "Référence : Le|bas kiā|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 209\n",
      "Référence : a|bas lūŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 210\n",
      "Référence : Le|bas lūŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 211\n",
      "Référence : n|bas zém|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 212\n",
      "Référence : Le|bas fɔ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 213\n",
      "Référence : m|bas bhʉ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 214\n",
      "Référence : ŋ|bas kak|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 215\n",
      "Référence : Le|bas kōk|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 216\n",
      "Référence : Me|bas laŋ |bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 217\n",
      "Référence : n|bas zɔŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 218\n",
      "Référence : a|bas kém|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 219\n",
      "Référence : n|bas cu|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 220\n",
      "Référence : n|bas tsem|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 221\n",
      "Référence : Sé|haut sā|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 222\n",
      "Référence : n|bas záŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 223\n",
      "Référence : ŋ|bas kyɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 224\n",
      "Référence : Le|bas lúŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 225\n",
      "Référence : N|haut chʉ̄ |moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 226\n",
      "Référence : n|bas dō|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 227\n",
      "Référence : Le|bas kwɛ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 228\n",
      "Référence : m|bas bɛ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 229\n",
      "Référence : Le|bas ká|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 230\n",
      "Référence : a|bas fu'|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 231\n",
      "Référence : ŋ|bas kák|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 232\n",
      "Référence : Sé|haut sā|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 233\n",
      "Référence : m|haut bɛ́t|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 234\n",
      "Référence : n|bas tsɔ'|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 235\n",
      "Référence : Le|bas kwɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 236\n",
      "Référence : n|bas zeŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 237\n",
      "Référence : Le|bas kwɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 238\n",
      "Référence : a|bas ká|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 239\n",
      "Référence : a|bas tū'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 240\n",
      "Référence : Le|bas lū'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 241\n",
      "Référence : m|bas bɛ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 242\n",
      "Référence : a|bas tā|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 243\n",
      "Référence : m|bas bɔ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 244\n",
      "Référence : m|bas baŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 245\n",
      "Référence : Le|bas sɔŋ |bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 246\n",
      "Référence : m|bas bí|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 247\n",
      "Référence : m|bas baŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 248\n",
      "Référence : m|haut bɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 249\n",
      "Référence : a|bas tū'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 250\n",
      "Référence : m|haut bɔ̄k |moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 251\n",
      "Référence : n|bas tɛ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 252\n",
      "Référence : a|bas kɔ̄'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 253\n",
      "Référence : m|bas bɔ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 254\n",
      "Référence : Le|bas ko|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 255\n",
      "Référence : Le|bas lu' |bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 256\n",
      "Référence : m|bas vhō|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 257\n",
      "Référence : M|bas vɛt|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 258\n",
      "Référence : Le|bas khʉ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 259\n",
      "Référence : Le|bas fāŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 260\n",
      "Référence : Le|bas cuŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 261\n",
      "Référence : É|haut sā'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 262\n",
      "Référence : a|bas fu'|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 263\n",
      "Référence : n|bas tsɔp|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 264\n",
      "Référence : n|haut tsɔ́ŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 265\n",
      "Référence : Le|bas lū'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 266\n",
      "Référence : n|haut dɔ́|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 267\n",
      "Référence : m|bas bīŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 268\n",
      "Référence : le|bas zen|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 269\n",
      "Référence : n|haut dɔ́ŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 270\n",
      "Référence : Le|bas kōk|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 271\n",
      "Référence : le|bas fem|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 272\n",
      "Référence : a|bas twɛ́t|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 273\n",
      "Référence : n|haut da|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 274\n",
      "Référence : Le|bas pāp|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 275\n",
      "Référence : n|bas tshɛ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 276\n",
      "Référence : m|bas bɔ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 277\n",
      "Référence : a|bas tā|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 278\n",
      "Référence : n|bas taŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 279\n",
      "Référence : a|bas piŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 280\n",
      "Référence : m|bas bhʉ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 281\n",
      "Référence : n|haut tsāp|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 282\n",
      "Référence : Le|bas kwɛt|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 283\n",
      "Référence : ŋ|bas ka'|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 284\n",
      "Référence : m|bas bɛt|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 285\n",
      "Référence : Le|bas fɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 286\n",
      "Référence : n|bas tsem|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 287\n",
      "Référence : Le|bas fhō|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 288\n",
      "Référence : n|haut dɔ́|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 289\n",
      "Référence : n|haut tɔ́|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 290\n",
      "Référence : N|bas tí |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 291\n",
      "Référence : Seŋ |bas ∅|∅ ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 292\n",
      "Référence : Le|bas pe|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 293\n",
      "Référence : m|haut báp|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 294\n",
      "Référence : n|bas dō|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 295\n",
      "Référence : n|bas tshi|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 296\n",
      "Référence : Le|bas kwɛ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 297\n",
      "Référence : Me|bas nū|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 298\n",
      "Référence : m|bas bí|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 299\n",
      "Référence : Le|bas lém|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 300\n",
      "Référence : ŋ|bas gāp |moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 301\n",
      "Référence : n|bas tɛ́ɛ́|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 302\n",
      "Référence : n|bas tǝ̄|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 303\n",
      "Référence : Le|bas lūŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 304\n",
      "Référence : Le|bas fa |bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 305\n",
      "Référence : N|haut zāʼ |moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 306\n",
      "Référence : Le|bas cūŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 307\n",
      "Référence : n|haut tāŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 308\n",
      "Référence : n|bas du|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 309\n",
      "Référence : a|bas fē|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 310\n",
      "Référence : Le|bas pē|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 311\n",
      "Référence : m|bas bɔ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 312\n",
      "Référence : m|haut bō|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 313\n",
      "Référence : ŋ|bas kā'|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 314\n",
      "Référence : M|haut vɛ́t |haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 315\n",
      "Référence : n|haut tāŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 316\n",
      "Référence : n|bas dɛ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 317\n",
      "Référence : n|haut táŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 318\n",
      "Référence : Le|bas kyɛt|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 319\n",
      "Référence : n|haut tswhī|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 320\n",
      "Référence : Le|bas kāŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 321\n",
      "Référence : ŋ|bas kyɛt|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 322\n",
      "Référence : n|bas tshɛ́|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 323\n",
      "Référence : a|bas tswɛ́t|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 324\n",
      "Référence : Le|bas fɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 325\n",
      "Référence : n|haut da|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 326\n",
      "Référence : M|haut vɛ̄t |moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 327\n",
      "Référence : Le|bas pē|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 328\n",
      "Référence : Le|bas kwɛ̄t|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 329\n",
      "Référence : n|bas zɔ̄ŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 330\n",
      "Référence : n|bas deŋ|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 331\n",
      "Référence : n|haut dáŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 332\n",
      "Référence : Le|bas lúŋ|haut ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 333\n",
      "Référence : n|bas tɔ̄ŋ|moyen ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 334\n",
      "Référence : Le|bas kak|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n",
      "\n",
      "🔴 Sample 335\n",
      "Référence : a|bas tu'|bas ∅|∅\n",
      "Prédit     : Le|bas gap|bas ∅|∅ ∅|∅\n"
     ]
    }
   ],
   "source": [
    "for i, (ref, pred) in enumerate(zip(all_refs, all_preds)):\n",
    "    if ref != pred:\n",
    "        print(f\"\\n🔴 Sample {i}\")\n",
    "        print(f\"Référence : {ref}\")\n",
    "        print(f\"Prédit     : {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3a90db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fichier_audio</th>\n",
       "      <th>prediction</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fichier_audio, prediction, reference]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtree = df_resultats[df_resultats['prediction'] == df_resultats['reference']]\n",
    "df_filtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e414ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_erreurs = df_resultats[df_resultats['prediction'] != df_resultats['reference']]\n",
    "len(df_erreurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2bb1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
